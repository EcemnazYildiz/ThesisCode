{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc46849",
   "metadata": {},
   "source": [
    "## Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bef016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Registered S3 method overwritten by 'rvest':\n",
      "  method            from\n",
      "  read_xml.response xml2\n",
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.1     ✔ purrr   0.3.2\n",
      "✔ tibble  3.1.0     ✔ dplyr   1.0.5\n",
      "✔ tidyr   1.1.3     ✔ stringr 1.4.0\n",
      "✔ readr   1.3.1     ✔ forcats 0.4.0\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘tidyr’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.6.3”── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::between()   masks data.table::between()\n",
      "✖ dplyr::filter()    masks stats::filter()\n",
      "✖ dplyr::first()     masks data.table::first()\n",
      "✖ dplyr::lag()       masks stats::lag()\n",
      "✖ dplyr::last()      masks data.table::last()\n",
      "✖ purrr::transpose() masks data.table::transpose()\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    as_data_frame, groups, union\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    compose, simplify\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    crossing\n",
      "\n",
      "The following object is masked from ‘package:tibble’:\n",
      "\n",
      "    as_data_frame\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Warning message:\n",
      "“package ‘lhs’ was built under R version 3.6.3”"
     ]
    }
   ],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "library(lhs)\n",
    "\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a098a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "The following object is masked from ‘package:igraph’:\n",
      "\n",
      "    groups\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "“package ‘factoextra’ was built under R version 3.6.3”Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n",
      "Loading required package: gridExtra\n",
      "Warning message:\n",
      "“package ‘gridExtra’ was built under R version 3.6.3”\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "source(paste0(folder.path,\"ThesisSetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"info_cascade_update_TDP_JPF_2020\" #\"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"/Users/ecemnaz.yildiz/Documents/NetLogo 6.0.4/Java\"\n",
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4090a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = \"info_cascade_update\" ##ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "\n",
    "training_set_size = 500 #75 #500\n",
    "training_set_seed = 9 #8\n",
    "training_set_date = \"2022-02-13\"\n",
    "\n",
    "test_set_size = 215 #30 #215\n",
    "test_set_seed = 8\n",
    "test_set_date = \"2022-02-12\"\n",
    "\n",
    "data.path = paste0(folder.path,\"Data_\",training_set_size,\"_Seed\",training_set_seed,\"/\")\n",
    "\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V3_RFE_mtrymultip2_\",model.type,\"_\",Sys.Date(),\"_\",format(Sys.time(), \"%H.%M\"),\"_\",training_set_size,\"_\",training_set_seed)\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71034",
   "metadata": {},
   "source": [
    "## Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7e24",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f148b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters #### Set model parameters Number of replications for each\n",
    "#### instance\n",
    "nofrep = 30 #############################\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "\n",
    "    feature_names = c(\n",
    "    \"max_links\",\n",
    "    \"evidence\",\n",
    "    \"sc-bel-prop\",\n",
    "    \"prop-likelihood\",\n",
    "    \"n_init_believers\",\n",
    "    \"prior-mean\",\n",
    "    \"prior-sd\",\n",
    "    \"expertise_influence\") \n",
    "    feature_ranges = data.table(  feature   = feature_names\n",
    "                                , min_range = c(2, 0, 0, 0, 0, 0, 0, 0)\n",
    "                                , max_range = c(500, 100, 5, 1, 100, 1, 1, 1)\n",
    "                               )\n",
    "\n",
    "# \n",
    "output_name = c(\"cl-prop-same\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "#mtry = 2\n",
    "mtry.multiplier = 2 # when 1, it is default, when 2, it is at most twice of defaults \n",
    "nperm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeeb6f",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ca5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "\n",
    "elimination.type = \"NRFE\" # or \"RFE\"\n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 11\n",
    "metarep = c(1:10)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 30\n",
    "test_ins = 215 #30 #215 ##c(100,400)\n",
    "train_ins_oneshot = 500 #75 #500\n",
    "train_ins_Ad = 500 #75 #500 ##50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameter\n",
    "p = 0.2 # elimination proportion\n",
    "# h = 1\n",
    "oob_allowance = 0.01\n",
    "\n",
    "seed.focus = 9 ##c(1,2,3,4,5,6,7,8,9,20)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "\n",
    "# Decide on strategy:\n",
    "elimination_start_iter = 5\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c171d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "test_set = data.table()\n",
    "for( t in test_set_size){\n",
    "    test_set.name= paste0(data.path,\"test_set_\",model.type,\"_\",t,\"_seed\",test_set_seed,\"_\",test_set_date,\".csv\")\n",
    "    test_set_Sub <- fread(test_set.name)  \n",
    "    \n",
    "    test_set = rbind(test_set, data.table(size = t, test_set_Sub))\n",
    "    \n",
    "    #assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c33a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "paste0(data.path,\"test_set_\",model.type,\"_\",t,\"_seed\",test_set_seed,\"_\",test_set_date,\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee16ba11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>size</th><th scope=col>max_links</th><th scope=col>evidence</th><th scope=col>sc-bel-prop</th><th scope=col>prop-likelihood</th><th scope=col>n_init_believers</th><th scope=col>prior-mean</th><th scope=col>prior-sd</th><th scope=col>expertise_influence</th><th scope=col>output</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>215        </td><td>189.62460  </td><td>91.883719  </td><td>3.4096457  </td><td>0.65294353 </td><td>21.931290  </td><td>0.81369670 </td><td>0.38252934 </td><td>0.546690542</td><td>48.22549   </td></tr>\n",
       "\t<tr><td>215        </td><td>472.26499  </td><td>28.560495  </td><td>1.1881089  </td><td>0.92273792 </td><td>80.046443  </td><td>0.98328880 </td><td>0.70990444 </td><td>0.304951987</td><td>43.75605   </td></tr>\n",
       "\t<tr><td>215        </td><td>302.24971  </td><td>26.433859  </td><td>2.8147611  </td><td>0.13756179 </td><td>66.341151  </td><td>0.22553450 </td><td>0.32349952 </td><td>0.884159073</td><td>47.58689   </td></tr>\n",
       "\t<tr><td>215        </td><td> 51.32996  </td><td>54.971811  </td><td>1.6453674  </td><td>0.95689327 </td><td>63.857945  </td><td>0.77174551 </td><td>0.09226774 </td><td>0.560788175</td><td>44.70953   </td></tr>\n",
       "\t<tr><td>215        </td><td> 31.44839  </td><td>50.460513  </td><td>0.2971720  </td><td>0.52391192 </td><td> 5.029048  </td><td>0.25692528 </td><td>0.32124878 </td><td>0.930769383</td><td>69.01723   </td></tr>\n",
       "\t<tr><td>215        </td><td>125.92689  </td><td>37.370317  </td><td>4.0521681  </td><td>0.82448262 </td><td>53.921749  </td><td>0.81556397 </td><td>0.26011453 </td><td>0.068728022</td><td>66.62976   </td></tr>\n",
       "\t<tr><td>215        </td><td> 95.03907  </td><td>18.922892  </td><td>0.2424934  </td><td>0.15100679 </td><td>45.736426  </td><td>0.98324116 </td><td>0.18267836 </td><td>0.568441012</td><td>49.07328   </td></tr>\n",
       "\t<tr><td>215        </td><td>144.51384  </td><td> 2.125038  </td><td>2.5202274  </td><td>0.07575313 </td><td>83.823701  </td><td>0.50919590 </td><td>0.74961552 </td><td>0.576853669</td><td>42.83901   </td></tr>\n",
       "\t<tr><td>215        </td><td>192.34215  </td><td>55.098017  </td><td>1.3591612  </td><td>0.28615150 </td><td>50.847169  </td><td>0.58258702 </td><td>0.98952283 </td><td>0.526410916</td><td>45.50651   </td></tr>\n",
       "\t<tr><td>215        </td><td>217.46080  </td><td>72.178856  </td><td>4.8820877  </td><td>0.76007216 </td><td>34.005433  </td><td>0.44495482 </td><td>0.99197711 </td><td>0.927555483</td><td>46.84836   </td></tr>\n",
       "\t<tr><td>215        </td><td> 12.78408  </td><td>65.232118  </td><td>3.7778047  </td><td>0.70315893 </td><td>88.412464  </td><td>0.24662605 </td><td>0.79247968 </td><td>0.222316002</td><td>45.01557   </td></tr>\n",
       "\t<tr><td>215        </td><td>250.00909  </td><td>64.884166  </td><td>4.8672709  </td><td>0.86261217 </td><td>24.145258  </td><td>0.98102564 </td><td>0.44723570 </td><td>0.227991919</td><td>54.32476   </td></tr>\n",
       "\t<tr><td>215        </td><td>136.06604  </td><td>46.618479  </td><td>0.5739030  </td><td>0.21017590 </td><td>58.030398  </td><td>0.01012270 </td><td>0.64254240 </td><td>0.821903769</td><td>46.01652   </td></tr>\n",
       "\t<tr><td>215        </td><td>  5.11121  </td><td>94.740174  </td><td>2.7858625  </td><td>0.90398539 </td><td>29.811258  </td><td>0.82318878 </td><td>0.55676634 </td><td>0.007820236</td><td>50.31103   </td></tr>\n",
       "\t<tr><td>215        </td><td>207.64485  </td><td>14.282201  </td><td>4.1457538  </td><td>0.19581487 </td><td>14.837153  </td><td>0.52654852 </td><td>0.66487021 </td><td>0.893159646</td><td>48.69165   </td></tr>\n",
       "\t<tr><td>215        </td><td>442.46073  </td><td>47.283616  </td><td>0.5102628  </td><td>0.83522562 </td><td>36.846694  </td><td>0.23003945 </td><td>0.92198722 </td><td>0.074520277</td><td>47.03399   </td></tr>\n",
       "\t<tr><td>215        </td><td> 29.02409  </td><td>53.429752  </td><td>1.2992951  </td><td>0.50566514 </td><td>14.898940  </td><td>0.63001561 </td><td>0.98925904 </td><td>0.159649456</td><td>50.27932   </td></tr>\n",
       "\t<tr><td>215        </td><td>106.51400  </td><td>24.041950  </td><td>3.3347448  </td><td>0.44274224 </td><td>60.509282  </td><td>0.06870073 </td><td>0.24745952 </td><td>0.022754202</td><td>77.96971   </td></tr>\n",
       "\t<tr><td>215        </td><td> 61.55091  </td><td>75.735762  </td><td>4.8364002  </td><td>0.03922675 </td><td>42.542258  </td><td>0.62634146 </td><td>0.21548472 </td><td>0.732479882</td><td>47.47501   </td></tr>\n",
       "\t<tr><td>215        </td><td>231.44218  </td><td>95.196420  </td><td>3.0711425  </td><td>0.22327928 </td><td>99.281789  </td><td>0.71213297 </td><td>0.94357023 </td><td>0.224489021</td><td>41.70140   </td></tr>\n",
       "\t<tr><td>215        </td><td> 49.13695  </td><td>55.657313  </td><td>1.2123565  </td><td>0.50484366 </td><td>50.428513  </td><td>0.88386295 </td><td>0.24595944 </td><td>0.949011229</td><td>59.94844   </td></tr>\n",
       "\t<tr><td>215        </td><td>323.07710  </td><td>46.927936  </td><td>0.9888268  </td><td>0.62271761 </td><td>60.358858  </td><td>0.70129681 </td><td>0.29743142 </td><td>0.522689946</td><td>44.66436   </td></tr>\n",
       "\t<tr><td>215        </td><td>193.14995  </td><td>96.926132  </td><td>3.2783270  </td><td>0.47743287 </td><td>18.759191  </td><td>0.88769187 </td><td>0.50424560 </td><td>0.871873983</td><td>50.56278   </td></tr>\n",
       "\t<tr><td>215        </td><td>139.85753  </td><td>24.120368  </td><td>4.7764685  </td><td>0.64560847 </td><td>38.563855  </td><td>0.33533168 </td><td>0.73544039 </td><td>0.509717776</td><td>46.52061   </td></tr>\n",
       "\t<tr><td>215        </td><td>332.77447  </td><td>44.181564  </td><td>1.6369996  </td><td>0.29747669 </td><td>50.700050  </td><td>0.20530623 </td><td>0.60612865 </td><td>0.578425702</td><td>45.60197   </td></tr>\n",
       "\t<tr><td>215        </td><td>420.28215  </td><td>52.482850  </td><td>2.0590338  </td><td>0.30093558 </td><td>76.543967  </td><td>0.75824877 </td><td>0.30879783 </td><td>0.811241168</td><td>46.10335   </td></tr>\n",
       "\t<tr><td>215        </td><td>308.02084  </td><td> 2.233376  </td><td>1.8459750  </td><td>0.80467476 </td><td>85.771723  </td><td>0.30926778 </td><td>0.75684483 </td><td>0.543134850</td><td>42.67607   </td></tr>\n",
       "\t<tr><td>215        </td><td>103.83433  </td><td>40.184390  </td><td>0.2477337  </td><td>0.02307229 </td><td>90.091970  </td><td>0.35665736 </td><td>0.73029299 </td><td>0.998511932</td><td>42.46859   </td></tr>\n",
       "\t<tr><td>215        </td><td>408.83604  </td><td>76.583869  </td><td>2.8265192  </td><td>0.59582851 </td><td> 9.206042  </td><td>0.07921726 </td><td>0.79344019 </td><td>0.868101592</td><td>49.70828   </td></tr>\n",
       "\t<tr><td>215        </td><td> 24.59514  </td><td>72.818628  </td><td>2.6397364  </td><td>0.27839785 </td><td>69.401344  </td><td>0.85519684 </td><td>0.37090632 </td><td>0.195744395</td><td>53.09835   </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>215         </td><td>177.248554  </td><td>41.185787   </td><td>3.86267210  </td><td>0.919917105 </td><td>72.805793   </td><td>0.040249445 </td><td>0.2788769   </td><td>0.7992048196</td><td>52.86172    </td></tr>\n",
       "\t<tr><td>215         </td><td>277.894186  </td><td>68.906074   </td><td>3.52290366  </td><td>0.838347905 </td><td>27.134682   </td><td>0.080432671 </td><td>0.1171693   </td><td>0.5104555276</td><td>47.55177    </td></tr>\n",
       "\t<tr><td>215         </td><td>161.520457  </td><td>87.662020   </td><td>3.51517315  </td><td>0.922756814 </td><td> 5.718915   </td><td>0.386630245 </td><td>0.8706690   </td><td>0.8989025950</td><td>50.87685    </td></tr>\n",
       "\t<tr><td>215         </td><td>341.596039  </td><td>26.815043   </td><td>3.73300355  </td><td>0.693576964 </td><td>17.288938   </td><td>0.220844093 </td><td>0.7460399   </td><td>0.5758263865</td><td>48.41421    </td></tr>\n",
       "\t<tr><td>215         </td><td>279.908264  </td><td>89.891927   </td><td>3.66509943  </td><td>0.984810607 </td><td>63.857291   </td><td>0.394020131 </td><td>0.6725865   </td><td>0.0859814065</td><td>44.52115    </td></tr>\n",
       "\t<tr><td>215         </td><td>309.341022  </td><td>49.919762   </td><td>3.31763226  </td><td>0.117485399 </td><td>61.645094   </td><td>0.970731398 </td><td>0.6939298   </td><td>0.0673981805</td><td>46.74303    </td></tr>\n",
       "\t<tr><td>215         </td><td>444.006908  </td><td>26.170509   </td><td>2.38956938  </td><td>0.210591943 </td><td>74.424024   </td><td>0.036066287 </td><td>0.3780423   </td><td>0.2364977230</td><td>52.34605    </td></tr>\n",
       "\t<tr><td>215         </td><td>443.364905  </td><td>98.687112   </td><td>0.66604676  </td><td>0.004886084 </td><td> 2.511227   </td><td>0.726659650 </td><td>0.8434329   </td><td>0.9879953098</td><td>50.66971    </td></tr>\n",
       "\t<tr><td>215         </td><td>412.089648  </td><td>54.466311   </td><td>1.42491029  </td><td>0.626792011 </td><td>81.649864   </td><td>0.032911561 </td><td>0.6106258   </td><td>0.3494069206</td><td>43.69874    </td></tr>\n",
       "\t<tr><td>215         </td><td>324.514052  </td><td>45.887418   </td><td>4.00904545  </td><td>0.503256798 </td><td>75.177504   </td><td>0.443241753 </td><td>0.7626485   </td><td>0.2368719387</td><td>43.41827    </td></tr>\n",
       "\t<tr><td>215         </td><td>363.080797  </td><td>62.913324   </td><td>0.14798923  </td><td>0.191133203 </td><td>73.994996   </td><td>0.038418766 </td><td>0.8046029   </td><td>0.1590003879</td><td>44.58449    </td></tr>\n",
       "\t<tr><td>215         </td><td>139.950413  </td><td>67.533314   </td><td>0.80002354  </td><td>0.228807879 </td><td>77.683905   </td><td>0.320098264 </td><td>0.4104565   </td><td>0.1155215886</td><td>45.37893    </td></tr>\n",
       "\t<tr><td>215         </td><td>308.831899  </td><td>79.694989   </td><td>1.47196140  </td><td>0.257790751 </td><td>17.254810   </td><td>0.555212180 </td><td>0.8976959   </td><td>0.2864136912</td><td>48.40431    </td></tr>\n",
       "\t<tr><td>215         </td><td>463.817083  </td><td>82.767226   </td><td>1.86815946  </td><td>0.941645256 </td><td>66.834413   </td><td>0.052980745 </td><td>0.8092231   </td><td>0.6553578568</td><td>44.33724    </td></tr>\n",
       "\t<tr><td>215         </td><td>440.597788  </td><td>51.611891   </td><td>4.60703735  </td><td>0.491937881 </td><td>60.918759   </td><td>0.490204060 </td><td>0.2352247   </td><td>0.9253918030</td><td>44.63585    </td></tr>\n",
       "\t<tr><td>215         </td><td>179.776660  </td><td>55.944449   </td><td>3.49788418  </td><td>0.201063529 </td><td>54.867170   </td><td>0.225023965 </td><td>0.9433692   </td><td>0.7821568286</td><td>45.19206    </td></tr>\n",
       "\t<tr><td>215         </td><td> 69.041930  </td><td> 9.398539   </td><td>1.60025186  </td><td>0.557395515 </td><td>63.857278   </td><td>0.720998303 </td><td>0.3814338   </td><td>0.8757952868</td><td>46.09784    </td></tr>\n",
       "\t<tr><td>215         </td><td>128.516500  </td><td>73.179796   </td><td>3.91474079  </td><td>0.211249739 </td><td>71.606288   </td><td>0.007910235 </td><td>0.1089412   </td><td>0.4653379526</td><td>46.38365    </td></tr>\n",
       "\t<tr><td>215         </td><td>  7.439371  </td><td>49.624655   </td><td>1.36742565  </td><td>0.933258044 </td><td>98.868166   </td><td>0.679803449 </td><td>0.4100317   </td><td>0.4066093541</td><td>48.66500    </td></tr>\n",
       "\t<tr><td>215         </td><td>351.602468  </td><td>28.359671   </td><td>4.75705109  </td><td>0.997278647 </td><td>29.991592   </td><td>0.941289967 </td><td>0.5473462   </td><td>0.7705731990</td><td>48.80482    </td></tr>\n",
       "\t<tr><td>215         </td><td>400.937686  </td><td> 1.246609   </td><td>0.09233047  </td><td>0.369692210 </td><td>36.476186   </td><td>0.769114728 </td><td>0.1203108   </td><td>0.4972614627</td><td>46.71185    </td></tr>\n",
       "\t<tr><td>215         </td><td> 92.258614  </td><td>95.800799   </td><td>4.51159603  </td><td>0.017429590 </td><td>25.114452   </td><td>0.832074601 </td><td>0.2776301   </td><td>0.4586726245</td><td>48.55179    </td></tr>\n",
       "\t<tr><td>215         </td><td>206.511425  </td><td>66.266057   </td><td>3.22191271  </td><td>0.622198241 </td><td>51.172902   </td><td>0.862836434 </td><td>0.5540932   </td><td>0.7844405759</td><td>46.36150    </td></tr>\n",
       "\t<tr><td>215         </td><td> 43.004799  </td><td>46.409903   </td><td>2.12385031  </td><td>0.009826274 </td><td>62.441224   </td><td>0.602738649 </td><td>0.7652706   </td><td>0.7916735194</td><td>44.31869    </td></tr>\n",
       "\t<tr><td>215         </td><td> 82.297681  </td><td>33.928176   </td><td>4.26993759  </td><td>0.781078116 </td><td>66.167562   </td><td>0.278714189 </td><td>0.4408367   </td><td>0.0840449068</td><td>46.72277    </td></tr>\n",
       "\t<tr><td>215         </td><td> 84.109696  </td><td>58.906824   </td><td>4.02700014  </td><td>0.851963063 </td><td>66.443150   </td><td>0.702157915 </td><td>0.7372790   </td><td>0.0234988490</td><td>44.46110    </td></tr>\n",
       "\t<tr><td>215         </td><td> 18.843968  </td><td>11.169266   </td><td>3.40911530  </td><td>0.362492867 </td><td>98.297228   </td><td>0.680886404 </td><td>0.0464128   </td><td>0.4350559353</td><td>44.03076    </td></tr>\n",
       "\t<tr><td>215         </td><td>175.882152  </td><td> 8.787802   </td><td>3.22145617  </td><td>0.610207854 </td><td>34.830814   </td><td>0.625565843 </td><td>0.4323407   </td><td>0.0006071492</td><td>47.71130    </td></tr>\n",
       "\t<tr><td>215         </td><td> 23.932372  </td><td>84.962382   </td><td>3.39344675  </td><td>0.043506402 </td><td>78.993535   </td><td>0.380426052 </td><td>0.9805016   </td><td>0.0095748459</td><td>43.32907    </td></tr>\n",
       "\t<tr><td>215         </td><td>265.445444  </td><td>65.863481   </td><td>0.54603362  </td><td>0.612432753 </td><td>90.733425   </td><td>0.996609690 </td><td>0.4822593   </td><td>0.3558607444</td><td>43.84758    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " size & max\\_links & evidence & sc-bel-prop & prop-likelihood & n\\_init\\_believers & prior-mean & prior-sd & expertise\\_influence & output\\\\\n",
       "\\hline\n",
       "\t 215         & 189.62460   & 91.883719   & 3.4096457   & 0.65294353  & 21.931290   & 0.81369670  & 0.38252934  & 0.546690542 & 48.22549   \\\\\n",
       "\t 215         & 472.26499   & 28.560495   & 1.1881089   & 0.92273792  & 80.046443   & 0.98328880  & 0.70990444  & 0.304951987 & 43.75605   \\\\\n",
       "\t 215         & 302.24971   & 26.433859   & 2.8147611   & 0.13756179  & 66.341151   & 0.22553450  & 0.32349952  & 0.884159073 & 47.58689   \\\\\n",
       "\t 215         &  51.32996   & 54.971811   & 1.6453674   & 0.95689327  & 63.857945   & 0.77174551  & 0.09226774  & 0.560788175 & 44.70953   \\\\\n",
       "\t 215         &  31.44839   & 50.460513   & 0.2971720   & 0.52391192  &  5.029048   & 0.25692528  & 0.32124878  & 0.930769383 & 69.01723   \\\\\n",
       "\t 215         & 125.92689   & 37.370317   & 4.0521681   & 0.82448262  & 53.921749   & 0.81556397  & 0.26011453  & 0.068728022 & 66.62976   \\\\\n",
       "\t 215         &  95.03907   & 18.922892   & 0.2424934   & 0.15100679  & 45.736426   & 0.98324116  & 0.18267836  & 0.568441012 & 49.07328   \\\\\n",
       "\t 215         & 144.51384   &  2.125038   & 2.5202274   & 0.07575313  & 83.823701   & 0.50919590  & 0.74961552  & 0.576853669 & 42.83901   \\\\\n",
       "\t 215         & 192.34215   & 55.098017   & 1.3591612   & 0.28615150  & 50.847169   & 0.58258702  & 0.98952283  & 0.526410916 & 45.50651   \\\\\n",
       "\t 215         & 217.46080   & 72.178856   & 4.8820877   & 0.76007216  & 34.005433   & 0.44495482  & 0.99197711  & 0.927555483 & 46.84836   \\\\\n",
       "\t 215         &  12.78408   & 65.232118   & 3.7778047   & 0.70315893  & 88.412464   & 0.24662605  & 0.79247968  & 0.222316002 & 45.01557   \\\\\n",
       "\t 215         & 250.00909   & 64.884166   & 4.8672709   & 0.86261217  & 24.145258   & 0.98102564  & 0.44723570  & 0.227991919 & 54.32476   \\\\\n",
       "\t 215         & 136.06604   & 46.618479   & 0.5739030   & 0.21017590  & 58.030398   & 0.01012270  & 0.64254240  & 0.821903769 & 46.01652   \\\\\n",
       "\t 215         &   5.11121   & 94.740174   & 2.7858625   & 0.90398539  & 29.811258   & 0.82318878  & 0.55676634  & 0.007820236 & 50.31103   \\\\\n",
       "\t 215         & 207.64485   & 14.282201   & 4.1457538   & 0.19581487  & 14.837153   & 0.52654852  & 0.66487021  & 0.893159646 & 48.69165   \\\\\n",
       "\t 215         & 442.46073   & 47.283616   & 0.5102628   & 0.83522562  & 36.846694   & 0.23003945  & 0.92198722  & 0.074520277 & 47.03399   \\\\\n",
       "\t 215         &  29.02409   & 53.429752   & 1.2992951   & 0.50566514  & 14.898940   & 0.63001561  & 0.98925904  & 0.159649456 & 50.27932   \\\\\n",
       "\t 215         & 106.51400   & 24.041950   & 3.3347448   & 0.44274224  & 60.509282   & 0.06870073  & 0.24745952  & 0.022754202 & 77.96971   \\\\\n",
       "\t 215         &  61.55091   & 75.735762   & 4.8364002   & 0.03922675  & 42.542258   & 0.62634146  & 0.21548472  & 0.732479882 & 47.47501   \\\\\n",
       "\t 215         & 231.44218   & 95.196420   & 3.0711425   & 0.22327928  & 99.281789   & 0.71213297  & 0.94357023  & 0.224489021 & 41.70140   \\\\\n",
       "\t 215         &  49.13695   & 55.657313   & 1.2123565   & 0.50484366  & 50.428513   & 0.88386295  & 0.24595944  & 0.949011229 & 59.94844   \\\\\n",
       "\t 215         & 323.07710   & 46.927936   & 0.9888268   & 0.62271761  & 60.358858   & 0.70129681  & 0.29743142  & 0.522689946 & 44.66436   \\\\\n",
       "\t 215         & 193.14995   & 96.926132   & 3.2783270   & 0.47743287  & 18.759191   & 0.88769187  & 0.50424560  & 0.871873983 & 50.56278   \\\\\n",
       "\t 215         & 139.85753   & 24.120368   & 4.7764685   & 0.64560847  & 38.563855   & 0.33533168  & 0.73544039  & 0.509717776 & 46.52061   \\\\\n",
       "\t 215         & 332.77447   & 44.181564   & 1.6369996   & 0.29747669  & 50.700050   & 0.20530623  & 0.60612865  & 0.578425702 & 45.60197   \\\\\n",
       "\t 215         & 420.28215   & 52.482850   & 2.0590338   & 0.30093558  & 76.543967   & 0.75824877  & 0.30879783  & 0.811241168 & 46.10335   \\\\\n",
       "\t 215         & 308.02084   &  2.233376   & 1.8459750   & 0.80467476  & 85.771723   & 0.30926778  & 0.75684483  & 0.543134850 & 42.67607   \\\\\n",
       "\t 215         & 103.83433   & 40.184390   & 0.2477337   & 0.02307229  & 90.091970   & 0.35665736  & 0.73029299  & 0.998511932 & 42.46859   \\\\\n",
       "\t 215         & 408.83604   & 76.583869   & 2.8265192   & 0.59582851  &  9.206042   & 0.07921726  & 0.79344019  & 0.868101592 & 49.70828   \\\\\n",
       "\t 215         &  24.59514   & 72.818628   & 2.6397364   & 0.27839785  & 69.401344   & 0.85519684  & 0.37090632  & 0.195744395 & 53.09835   \\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t 215          & 177.248554   & 41.185787    & 3.86267210   & 0.919917105  & 72.805793    & 0.040249445  & 0.2788769    & 0.7992048196 & 52.86172    \\\\\n",
       "\t 215          & 277.894186   & 68.906074    & 3.52290366   & 0.838347905  & 27.134682    & 0.080432671  & 0.1171693    & 0.5104555276 & 47.55177    \\\\\n",
       "\t 215          & 161.520457   & 87.662020    & 3.51517315   & 0.922756814  &  5.718915    & 0.386630245  & 0.8706690    & 0.8989025950 & 50.87685    \\\\\n",
       "\t 215          & 341.596039   & 26.815043    & 3.73300355   & 0.693576964  & 17.288938    & 0.220844093  & 0.7460399    & 0.5758263865 & 48.41421    \\\\\n",
       "\t 215          & 279.908264   & 89.891927    & 3.66509943   & 0.984810607  & 63.857291    & 0.394020131  & 0.6725865    & 0.0859814065 & 44.52115    \\\\\n",
       "\t 215          & 309.341022   & 49.919762    & 3.31763226   & 0.117485399  & 61.645094    & 0.970731398  & 0.6939298    & 0.0673981805 & 46.74303    \\\\\n",
       "\t 215          & 444.006908   & 26.170509    & 2.38956938   & 0.210591943  & 74.424024    & 0.036066287  & 0.3780423    & 0.2364977230 & 52.34605    \\\\\n",
       "\t 215          & 443.364905   & 98.687112    & 0.66604676   & 0.004886084  &  2.511227    & 0.726659650  & 0.8434329    & 0.9879953098 & 50.66971    \\\\\n",
       "\t 215          & 412.089648   & 54.466311    & 1.42491029   & 0.626792011  & 81.649864    & 0.032911561  & 0.6106258    & 0.3494069206 & 43.69874    \\\\\n",
       "\t 215          & 324.514052   & 45.887418    & 4.00904545   & 0.503256798  & 75.177504    & 0.443241753  & 0.7626485    & 0.2368719387 & 43.41827    \\\\\n",
       "\t 215          & 363.080797   & 62.913324    & 0.14798923   & 0.191133203  & 73.994996    & 0.038418766  & 0.8046029    & 0.1590003879 & 44.58449    \\\\\n",
       "\t 215          & 139.950413   & 67.533314    & 0.80002354   & 0.228807879  & 77.683905    & 0.320098264  & 0.4104565    & 0.1155215886 & 45.37893    \\\\\n",
       "\t 215          & 308.831899   & 79.694989    & 1.47196140   & 0.257790751  & 17.254810    & 0.555212180  & 0.8976959    & 0.2864136912 & 48.40431    \\\\\n",
       "\t 215          & 463.817083   & 82.767226    & 1.86815946   & 0.941645256  & 66.834413    & 0.052980745  & 0.8092231    & 0.6553578568 & 44.33724    \\\\\n",
       "\t 215          & 440.597788   & 51.611891    & 4.60703735   & 0.491937881  & 60.918759    & 0.490204060  & 0.2352247    & 0.9253918030 & 44.63585    \\\\\n",
       "\t 215          & 179.776660   & 55.944449    & 3.49788418   & 0.201063529  & 54.867170    & 0.225023965  & 0.9433692    & 0.7821568286 & 45.19206    \\\\\n",
       "\t 215          &  69.041930   &  9.398539    & 1.60025186   & 0.557395515  & 63.857278    & 0.720998303  & 0.3814338    & 0.8757952868 & 46.09784    \\\\\n",
       "\t 215          & 128.516500   & 73.179796    & 3.91474079   & 0.211249739  & 71.606288    & 0.007910235  & 0.1089412    & 0.4653379526 & 46.38365    \\\\\n",
       "\t 215          &   7.439371   & 49.624655    & 1.36742565   & 0.933258044  & 98.868166    & 0.679803449  & 0.4100317    & 0.4066093541 & 48.66500    \\\\\n",
       "\t 215          & 351.602468   & 28.359671    & 4.75705109   & 0.997278647  & 29.991592    & 0.941289967  & 0.5473462    & 0.7705731990 & 48.80482    \\\\\n",
       "\t 215          & 400.937686   &  1.246609    & 0.09233047   & 0.369692210  & 36.476186    & 0.769114728  & 0.1203108    & 0.4972614627 & 46.71185    \\\\\n",
       "\t 215          &  92.258614   & 95.800799    & 4.51159603   & 0.017429590  & 25.114452    & 0.832074601  & 0.2776301    & 0.4586726245 & 48.55179    \\\\\n",
       "\t 215          & 206.511425   & 66.266057    & 3.22191271   & 0.622198241  & 51.172902    & 0.862836434  & 0.5540932    & 0.7844405759 & 46.36150    \\\\\n",
       "\t 215          &  43.004799   & 46.409903    & 2.12385031   & 0.009826274  & 62.441224    & 0.602738649  & 0.7652706    & 0.7916735194 & 44.31869    \\\\\n",
       "\t 215          &  82.297681   & 33.928176    & 4.26993759   & 0.781078116  & 66.167562    & 0.278714189  & 0.4408367    & 0.0840449068 & 46.72277    \\\\\n",
       "\t 215          &  84.109696   & 58.906824    & 4.02700014   & 0.851963063  & 66.443150    & 0.702157915  & 0.7372790    & 0.0234988490 & 44.46110    \\\\\n",
       "\t 215          &  18.843968   & 11.169266    & 3.40911530   & 0.362492867  & 98.297228    & 0.680886404  & 0.0464128    & 0.4350559353 & 44.03076    \\\\\n",
       "\t 215          & 175.882152   &  8.787802    & 3.22145617   & 0.610207854  & 34.830814    & 0.625565843  & 0.4323407    & 0.0006071492 & 47.71130    \\\\\n",
       "\t 215          &  23.932372   & 84.962382    & 3.39344675   & 0.043506402  & 78.993535    & 0.380426052  & 0.9805016    & 0.0095748459 & 43.32907    \\\\\n",
       "\t 215          & 265.445444   & 65.863481    & 0.54603362   & 0.612432753  & 90.733425    & 0.996609690  & 0.4822593    & 0.3558607444 & 43.84758    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| size | max_links | evidence | sc-bel-prop | prop-likelihood | n_init_believers | prior-mean | prior-sd | expertise_influence | output |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 215         | 189.62460   | 91.883719   | 3.4096457   | 0.65294353  | 21.931290   | 0.81369670  | 0.38252934  | 0.546690542 | 48.22549    |\n",
       "| 215         | 472.26499   | 28.560495   | 1.1881089   | 0.92273792  | 80.046443   | 0.98328880  | 0.70990444  | 0.304951987 | 43.75605    |\n",
       "| 215         | 302.24971   | 26.433859   | 2.8147611   | 0.13756179  | 66.341151   | 0.22553450  | 0.32349952  | 0.884159073 | 47.58689    |\n",
       "| 215         |  51.32996   | 54.971811   | 1.6453674   | 0.95689327  | 63.857945   | 0.77174551  | 0.09226774  | 0.560788175 | 44.70953    |\n",
       "| 215         |  31.44839   | 50.460513   | 0.2971720   | 0.52391192  |  5.029048   | 0.25692528  | 0.32124878  | 0.930769383 | 69.01723    |\n",
       "| 215         | 125.92689   | 37.370317   | 4.0521681   | 0.82448262  | 53.921749   | 0.81556397  | 0.26011453  | 0.068728022 | 66.62976    |\n",
       "| 215         |  95.03907   | 18.922892   | 0.2424934   | 0.15100679  | 45.736426   | 0.98324116  | 0.18267836  | 0.568441012 | 49.07328    |\n",
       "| 215         | 144.51384   |  2.125038   | 2.5202274   | 0.07575313  | 83.823701   | 0.50919590  | 0.74961552  | 0.576853669 | 42.83901    |\n",
       "| 215         | 192.34215   | 55.098017   | 1.3591612   | 0.28615150  | 50.847169   | 0.58258702  | 0.98952283  | 0.526410916 | 45.50651    |\n",
       "| 215         | 217.46080   | 72.178856   | 4.8820877   | 0.76007216  | 34.005433   | 0.44495482  | 0.99197711  | 0.927555483 | 46.84836    |\n",
       "| 215         |  12.78408   | 65.232118   | 3.7778047   | 0.70315893  | 88.412464   | 0.24662605  | 0.79247968  | 0.222316002 | 45.01557    |\n",
       "| 215         | 250.00909   | 64.884166   | 4.8672709   | 0.86261217  | 24.145258   | 0.98102564  | 0.44723570  | 0.227991919 | 54.32476    |\n",
       "| 215         | 136.06604   | 46.618479   | 0.5739030   | 0.21017590  | 58.030398   | 0.01012270  | 0.64254240  | 0.821903769 | 46.01652    |\n",
       "| 215         |   5.11121   | 94.740174   | 2.7858625   | 0.90398539  | 29.811258   | 0.82318878  | 0.55676634  | 0.007820236 | 50.31103    |\n",
       "| 215         | 207.64485   | 14.282201   | 4.1457538   | 0.19581487  | 14.837153   | 0.52654852  | 0.66487021  | 0.893159646 | 48.69165    |\n",
       "| 215         | 442.46073   | 47.283616   | 0.5102628   | 0.83522562  | 36.846694   | 0.23003945  | 0.92198722  | 0.074520277 | 47.03399    |\n",
       "| 215         |  29.02409   | 53.429752   | 1.2992951   | 0.50566514  | 14.898940   | 0.63001561  | 0.98925904  | 0.159649456 | 50.27932    |\n",
       "| 215         | 106.51400   | 24.041950   | 3.3347448   | 0.44274224  | 60.509282   | 0.06870073  | 0.24745952  | 0.022754202 | 77.96971    |\n",
       "| 215         |  61.55091   | 75.735762   | 4.8364002   | 0.03922675  | 42.542258   | 0.62634146  | 0.21548472  | 0.732479882 | 47.47501    |\n",
       "| 215         | 231.44218   | 95.196420   | 3.0711425   | 0.22327928  | 99.281789   | 0.71213297  | 0.94357023  | 0.224489021 | 41.70140    |\n",
       "| 215         |  49.13695   | 55.657313   | 1.2123565   | 0.50484366  | 50.428513   | 0.88386295  | 0.24595944  | 0.949011229 | 59.94844    |\n",
       "| 215         | 323.07710   | 46.927936   | 0.9888268   | 0.62271761  | 60.358858   | 0.70129681  | 0.29743142  | 0.522689946 | 44.66436    |\n",
       "| 215         | 193.14995   | 96.926132   | 3.2783270   | 0.47743287  | 18.759191   | 0.88769187  | 0.50424560  | 0.871873983 | 50.56278    |\n",
       "| 215         | 139.85753   | 24.120368   | 4.7764685   | 0.64560847  | 38.563855   | 0.33533168  | 0.73544039  | 0.509717776 | 46.52061    |\n",
       "| 215         | 332.77447   | 44.181564   | 1.6369996   | 0.29747669  | 50.700050   | 0.20530623  | 0.60612865  | 0.578425702 | 45.60197    |\n",
       "| 215         | 420.28215   | 52.482850   | 2.0590338   | 0.30093558  | 76.543967   | 0.75824877  | 0.30879783  | 0.811241168 | 46.10335    |\n",
       "| 215         | 308.02084   |  2.233376   | 1.8459750   | 0.80467476  | 85.771723   | 0.30926778  | 0.75684483  | 0.543134850 | 42.67607    |\n",
       "| 215         | 103.83433   | 40.184390   | 0.2477337   | 0.02307229  | 90.091970   | 0.35665736  | 0.73029299  | 0.998511932 | 42.46859    |\n",
       "| 215         | 408.83604   | 76.583869   | 2.8265192   | 0.59582851  |  9.206042   | 0.07921726  | 0.79344019  | 0.868101592 | 49.70828    |\n",
       "| 215         |  24.59514   | 72.818628   | 2.6397364   | 0.27839785  | 69.401344   | 0.85519684  | 0.37090632  | 0.195744395 | 53.09835    |\n",
       "| ... | ... | ... | ... | ... | ... | ... | ... | ... | ... |\n",
       "| 215          | 177.248554   | 41.185787    | 3.86267210   | 0.919917105  | 72.805793    | 0.040249445  | 0.2788769    | 0.7992048196 | 52.86172     |\n",
       "| 215          | 277.894186   | 68.906074    | 3.52290366   | 0.838347905  | 27.134682    | 0.080432671  | 0.1171693    | 0.5104555276 | 47.55177     |\n",
       "| 215          | 161.520457   | 87.662020    | 3.51517315   | 0.922756814  |  5.718915    | 0.386630245  | 0.8706690    | 0.8989025950 | 50.87685     |\n",
       "| 215          | 341.596039   | 26.815043    | 3.73300355   | 0.693576964  | 17.288938    | 0.220844093  | 0.7460399    | 0.5758263865 | 48.41421     |\n",
       "| 215          | 279.908264   | 89.891927    | 3.66509943   | 0.984810607  | 63.857291    | 0.394020131  | 0.6725865    | 0.0859814065 | 44.52115     |\n",
       "| 215          | 309.341022   | 49.919762    | 3.31763226   | 0.117485399  | 61.645094    | 0.970731398  | 0.6939298    | 0.0673981805 | 46.74303     |\n",
       "| 215          | 444.006908   | 26.170509    | 2.38956938   | 0.210591943  | 74.424024    | 0.036066287  | 0.3780423    | 0.2364977230 | 52.34605     |\n",
       "| 215          | 443.364905   | 98.687112    | 0.66604676   | 0.004886084  |  2.511227    | 0.726659650  | 0.8434329    | 0.9879953098 | 50.66971     |\n",
       "| 215          | 412.089648   | 54.466311    | 1.42491029   | 0.626792011  | 81.649864    | 0.032911561  | 0.6106258    | 0.3494069206 | 43.69874     |\n",
       "| 215          | 324.514052   | 45.887418    | 4.00904545   | 0.503256798  | 75.177504    | 0.443241753  | 0.7626485    | 0.2368719387 | 43.41827     |\n",
       "| 215          | 363.080797   | 62.913324    | 0.14798923   | 0.191133203  | 73.994996    | 0.038418766  | 0.8046029    | 0.1590003879 | 44.58449     |\n",
       "| 215          | 139.950413   | 67.533314    | 0.80002354   | 0.228807879  | 77.683905    | 0.320098264  | 0.4104565    | 0.1155215886 | 45.37893     |\n",
       "| 215          | 308.831899   | 79.694989    | 1.47196140   | 0.257790751  | 17.254810    | 0.555212180  | 0.8976959    | 0.2864136912 | 48.40431     |\n",
       "| 215          | 463.817083   | 82.767226    | 1.86815946   | 0.941645256  | 66.834413    | 0.052980745  | 0.8092231    | 0.6553578568 | 44.33724     |\n",
       "| 215          | 440.597788   | 51.611891    | 4.60703735   | 0.491937881  | 60.918759    | 0.490204060  | 0.2352247    | 0.9253918030 | 44.63585     |\n",
       "| 215          | 179.776660   | 55.944449    | 3.49788418   | 0.201063529  | 54.867170    | 0.225023965  | 0.9433692    | 0.7821568286 | 45.19206     |\n",
       "| 215          |  69.041930   |  9.398539    | 1.60025186   | 0.557395515  | 63.857278    | 0.720998303  | 0.3814338    | 0.8757952868 | 46.09784     |\n",
       "| 215          | 128.516500   | 73.179796    | 3.91474079   | 0.211249739  | 71.606288    | 0.007910235  | 0.1089412    | 0.4653379526 | 46.38365     |\n",
       "| 215          |   7.439371   | 49.624655    | 1.36742565   | 0.933258044  | 98.868166    | 0.679803449  | 0.4100317    | 0.4066093541 | 48.66500     |\n",
       "| 215          | 351.602468   | 28.359671    | 4.75705109   | 0.997278647  | 29.991592    | 0.941289967  | 0.5473462    | 0.7705731990 | 48.80482     |\n",
       "| 215          | 400.937686   |  1.246609    | 0.09233047   | 0.369692210  | 36.476186    | 0.769114728  | 0.1203108    | 0.4972614627 | 46.71185     |\n",
       "| 215          |  92.258614   | 95.800799    | 4.51159603   | 0.017429590  | 25.114452    | 0.832074601  | 0.2776301    | 0.4586726245 | 48.55179     |\n",
       "| 215          | 206.511425   | 66.266057    | 3.22191271   | 0.622198241  | 51.172902    | 0.862836434  | 0.5540932    | 0.7844405759 | 46.36150     |\n",
       "| 215          |  43.004799   | 46.409903    | 2.12385031   | 0.009826274  | 62.441224    | 0.602738649  | 0.7652706    | 0.7916735194 | 44.31869     |\n",
       "| 215          |  82.297681   | 33.928176    | 4.26993759   | 0.781078116  | 66.167562    | 0.278714189  | 0.4408367    | 0.0840449068 | 46.72277     |\n",
       "| 215          |  84.109696   | 58.906824    | 4.02700014   | 0.851963063  | 66.443150    | 0.702157915  | 0.7372790    | 0.0234988490 | 44.46110     |\n",
       "| 215          |  18.843968   | 11.169266    | 3.40911530   | 0.362492867  | 98.297228    | 0.680886404  | 0.0464128    | 0.4350559353 | 44.03076     |\n",
       "| 215          | 175.882152   |  8.787802    | 3.22145617   | 0.610207854  | 34.830814    | 0.625565843  | 0.4323407    | 0.0006071492 | 47.71130     |\n",
       "| 215          |  23.932372   | 84.962382    | 3.39344675   | 0.043506402  | 78.993535    | 0.380426052  | 0.9805016    | 0.0095748459 | 43.32907     |\n",
       "| 215          | 265.445444   | 65.863481    | 0.54603362   | 0.612432753  | 90.733425    | 0.996609690  | 0.4822593    | 0.3558607444 | 43.84758     |\n",
       "\n"
      ],
      "text/plain": [
       "    size max_links  evidence  sc-bel-prop prop-likelihood n_init_believers\n",
       "1   215  189.62460  91.883719 3.4096457   0.65294353      21.931290       \n",
       "2   215  472.26499  28.560495 1.1881089   0.92273792      80.046443       \n",
       "3   215  302.24971  26.433859 2.8147611   0.13756179      66.341151       \n",
       "4   215   51.32996  54.971811 1.6453674   0.95689327      63.857945       \n",
       "5   215   31.44839  50.460513 0.2971720   0.52391192       5.029048       \n",
       "6   215  125.92689  37.370317 4.0521681   0.82448262      53.921749       \n",
       "7   215   95.03907  18.922892 0.2424934   0.15100679      45.736426       \n",
       "8   215  144.51384   2.125038 2.5202274   0.07575313      83.823701       \n",
       "9   215  192.34215  55.098017 1.3591612   0.28615150      50.847169       \n",
       "10  215  217.46080  72.178856 4.8820877   0.76007216      34.005433       \n",
       "11  215   12.78408  65.232118 3.7778047   0.70315893      88.412464       \n",
       "12  215  250.00909  64.884166 4.8672709   0.86261217      24.145258       \n",
       "13  215  136.06604  46.618479 0.5739030   0.21017590      58.030398       \n",
       "14  215    5.11121  94.740174 2.7858625   0.90398539      29.811258       \n",
       "15  215  207.64485  14.282201 4.1457538   0.19581487      14.837153       \n",
       "16  215  442.46073  47.283616 0.5102628   0.83522562      36.846694       \n",
       "17  215   29.02409  53.429752 1.2992951   0.50566514      14.898940       \n",
       "18  215  106.51400  24.041950 3.3347448   0.44274224      60.509282       \n",
       "19  215   61.55091  75.735762 4.8364002   0.03922675      42.542258       \n",
       "20  215  231.44218  95.196420 3.0711425   0.22327928      99.281789       \n",
       "21  215   49.13695  55.657313 1.2123565   0.50484366      50.428513       \n",
       "22  215  323.07710  46.927936 0.9888268   0.62271761      60.358858       \n",
       "23  215  193.14995  96.926132 3.2783270   0.47743287      18.759191       \n",
       "24  215  139.85753  24.120368 4.7764685   0.64560847      38.563855       \n",
       "25  215  332.77447  44.181564 1.6369996   0.29747669      50.700050       \n",
       "26  215  420.28215  52.482850 2.0590338   0.30093558      76.543967       \n",
       "27  215  308.02084   2.233376 1.8459750   0.80467476      85.771723       \n",
       "28  215  103.83433  40.184390 0.2477337   0.02307229      90.091970       \n",
       "29  215  408.83604  76.583869 2.8265192   0.59582851       9.206042       \n",
       "30  215   24.59514  72.818628 2.6397364   0.27839785      69.401344       \n",
       "... ...  ...        ...       ...         ...             ...             \n",
       "186 215  177.248554 41.185787 3.86267210  0.919917105     72.805793       \n",
       "187 215  277.894186 68.906074 3.52290366  0.838347905     27.134682       \n",
       "188 215  161.520457 87.662020 3.51517315  0.922756814      5.718915       \n",
       "189 215  341.596039 26.815043 3.73300355  0.693576964     17.288938       \n",
       "190 215  279.908264 89.891927 3.66509943  0.984810607     63.857291       \n",
       "191 215  309.341022 49.919762 3.31763226  0.117485399     61.645094       \n",
       "192 215  444.006908 26.170509 2.38956938  0.210591943     74.424024       \n",
       "193 215  443.364905 98.687112 0.66604676  0.004886084      2.511227       \n",
       "194 215  412.089648 54.466311 1.42491029  0.626792011     81.649864       \n",
       "195 215  324.514052 45.887418 4.00904545  0.503256798     75.177504       \n",
       "196 215  363.080797 62.913324 0.14798923  0.191133203     73.994996       \n",
       "197 215  139.950413 67.533314 0.80002354  0.228807879     77.683905       \n",
       "198 215  308.831899 79.694989 1.47196140  0.257790751     17.254810       \n",
       "199 215  463.817083 82.767226 1.86815946  0.941645256     66.834413       \n",
       "200 215  440.597788 51.611891 4.60703735  0.491937881     60.918759       \n",
       "201 215  179.776660 55.944449 3.49788418  0.201063529     54.867170       \n",
       "202 215   69.041930  9.398539 1.60025186  0.557395515     63.857278       \n",
       "203 215  128.516500 73.179796 3.91474079  0.211249739     71.606288       \n",
       "204 215    7.439371 49.624655 1.36742565  0.933258044     98.868166       \n",
       "205 215  351.602468 28.359671 4.75705109  0.997278647     29.991592       \n",
       "206 215  400.937686  1.246609 0.09233047  0.369692210     36.476186       \n",
       "207 215   92.258614 95.800799 4.51159603  0.017429590     25.114452       \n",
       "208 215  206.511425 66.266057 3.22191271  0.622198241     51.172902       \n",
       "209 215   43.004799 46.409903 2.12385031  0.009826274     62.441224       \n",
       "210 215   82.297681 33.928176 4.26993759  0.781078116     66.167562       \n",
       "211 215   84.109696 58.906824 4.02700014  0.851963063     66.443150       \n",
       "212 215   18.843968 11.169266 3.40911530  0.362492867     98.297228       \n",
       "213 215  175.882152  8.787802 3.22145617  0.610207854     34.830814       \n",
       "214 215   23.932372 84.962382 3.39344675  0.043506402     78.993535       \n",
       "215 215  265.445444 65.863481 0.54603362  0.612432753     90.733425       \n",
       "    prior-mean  prior-sd   expertise_influence output  \n",
       "1   0.81369670  0.38252934 0.546690542         48.22549\n",
       "2   0.98328880  0.70990444 0.304951987         43.75605\n",
       "3   0.22553450  0.32349952 0.884159073         47.58689\n",
       "4   0.77174551  0.09226774 0.560788175         44.70953\n",
       "5   0.25692528  0.32124878 0.930769383         69.01723\n",
       "6   0.81556397  0.26011453 0.068728022         66.62976\n",
       "7   0.98324116  0.18267836 0.568441012         49.07328\n",
       "8   0.50919590  0.74961552 0.576853669         42.83901\n",
       "9   0.58258702  0.98952283 0.526410916         45.50651\n",
       "10  0.44495482  0.99197711 0.927555483         46.84836\n",
       "11  0.24662605  0.79247968 0.222316002         45.01557\n",
       "12  0.98102564  0.44723570 0.227991919         54.32476\n",
       "13  0.01012270  0.64254240 0.821903769         46.01652\n",
       "14  0.82318878  0.55676634 0.007820236         50.31103\n",
       "15  0.52654852  0.66487021 0.893159646         48.69165\n",
       "16  0.23003945  0.92198722 0.074520277         47.03399\n",
       "17  0.63001561  0.98925904 0.159649456         50.27932\n",
       "18  0.06870073  0.24745952 0.022754202         77.96971\n",
       "19  0.62634146  0.21548472 0.732479882         47.47501\n",
       "20  0.71213297  0.94357023 0.224489021         41.70140\n",
       "21  0.88386295  0.24595944 0.949011229         59.94844\n",
       "22  0.70129681  0.29743142 0.522689946         44.66436\n",
       "23  0.88769187  0.50424560 0.871873983         50.56278\n",
       "24  0.33533168  0.73544039 0.509717776         46.52061\n",
       "25  0.20530623  0.60612865 0.578425702         45.60197\n",
       "26  0.75824877  0.30879783 0.811241168         46.10335\n",
       "27  0.30926778  0.75684483 0.543134850         42.67607\n",
       "28  0.35665736  0.73029299 0.998511932         42.46859\n",
       "29  0.07921726  0.79344019 0.868101592         49.70828\n",
       "30  0.85519684  0.37090632 0.195744395         53.09835\n",
       "... ...         ...        ...                 ...     \n",
       "186 0.040249445 0.2788769  0.7992048196        52.86172\n",
       "187 0.080432671 0.1171693  0.5104555276        47.55177\n",
       "188 0.386630245 0.8706690  0.8989025950        50.87685\n",
       "189 0.220844093 0.7460399  0.5758263865        48.41421\n",
       "190 0.394020131 0.6725865  0.0859814065        44.52115\n",
       "191 0.970731398 0.6939298  0.0673981805        46.74303\n",
       "192 0.036066287 0.3780423  0.2364977230        52.34605\n",
       "193 0.726659650 0.8434329  0.9879953098        50.66971\n",
       "194 0.032911561 0.6106258  0.3494069206        43.69874\n",
       "195 0.443241753 0.7626485  0.2368719387        43.41827\n",
       "196 0.038418766 0.8046029  0.1590003879        44.58449\n",
       "197 0.320098264 0.4104565  0.1155215886        45.37893\n",
       "198 0.555212180 0.8976959  0.2864136912        48.40431\n",
       "199 0.052980745 0.8092231  0.6553578568        44.33724\n",
       "200 0.490204060 0.2352247  0.9253918030        44.63585\n",
       "201 0.225023965 0.9433692  0.7821568286        45.19206\n",
       "202 0.720998303 0.3814338  0.8757952868        46.09784\n",
       "203 0.007910235 0.1089412  0.4653379526        46.38365\n",
       "204 0.679803449 0.4100317  0.4066093541        48.66500\n",
       "205 0.941289967 0.5473462  0.7705731990        48.80482\n",
       "206 0.769114728 0.1203108  0.4972614627        46.71185\n",
       "207 0.832074601 0.2776301  0.4586726245        48.55179\n",
       "208 0.862836434 0.5540932  0.7844405759        46.36150\n",
       "209 0.602738649 0.7652706  0.7916735194        44.31869\n",
       "210 0.278714189 0.4408367  0.0840449068        46.72277\n",
       "211 0.702157915 0.7372790  0.0234988490        44.46110\n",
       "212 0.680886404 0.0464128  0.4350559353        44.03076\n",
       "213 0.625565843 0.4323407  0.0006071492        47.71130\n",
       "214 0.380426052 0.9805016  0.0095748459        43.32907\n",
       "215 0.996609690 0.4822593  0.3558607444        43.84758"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9329e",
   "metadata": {},
   "source": [
    "## Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fa50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,training_set_seed,training_set_size,training_set_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149c9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "9"
      ],
      "text/latex": [
       "9"
      ],
      "text/markdown": [
       "9"
      ],
      "text/plain": [
       "[1] 9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unique(adaptive_initial_data$seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08345fa",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ef3c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"seed : 9  Adaptive Sampling with Feature Selection section start time : 2022-03-01 23:08:13\"\n",
      "[1] \"seed : 9   rep : 1  Adaptive Sampling with Feature Selection section start time : 2022-03-01 23:08:13\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:08:14\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:10:47\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:10:48\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:13:50\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:13:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:16:28\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:16:29\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:19:59\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:20:00\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:23:31\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:23:33\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:26:53\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:26:55\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:30:39\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:30:41\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:34:38\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:34:40\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:41:41\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:41:43\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:46:22\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 2  Adaptive Sampling with Feature Selection section start time : 2022-03-01 23:46:23\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:46:24\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:53:43\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:53:43\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:56:08\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:56:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-01 23:59:22\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-01 23:59:23\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:02:53\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:02:53\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:05:51\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:05:52\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:09:18\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:09:19\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:12:49\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:12:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:18:17\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:18:19\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:22:44\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:22:45\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:26:00\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 3  Adaptive Sampling with Feature Selection section start time : 2022-03-02 00:26:01\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:26:01\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:28:10\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:28:11\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:31:19\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:31:19\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:34:08\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:34:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:36:38\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:36:38\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:39:10\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:39:12\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:41:56\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:41:57\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:43:55\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:43:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:47:21\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:47:23\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:50:33\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:50:34\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:53:02\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 4  Adaptive Sampling with Feature Selection section start time : 2022-03-02 00:53:04\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:53:04\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:55:52\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:55:53\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 00:58:37\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 00:58:37\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:01:06\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:01:07\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:04:06\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:04:07\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:06:50\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:06:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:10:53\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:10:54\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:12:53\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:12:54\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:15:47\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:15:48\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:17:39\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:17:40\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:19:33\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 5  Adaptive Sampling with Feature Selection section start time : 2022-03-02 01:19:34\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:19:35\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:22:21\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:22:21\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:24:50\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:24:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:26:56\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:26:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:29:39\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:29:40\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:33:36\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:33:37\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:35:58\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:35:59\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:41:25\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:41:27\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:47:46\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:47:47\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:49:40\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:49:41\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:51:56\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 6  Adaptive Sampling with Feature Selection section start time : 2022-03-02 01:51:57\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:51:58\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:55:05\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:55:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:56:41\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:56:42\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 01:59:25\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 01:59:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:03:05\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:03:06\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:07:49\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:07:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:11:32\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:11:33\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:13:48\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:13:50\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:17:23\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:17:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:19:45\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:19:47\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:21:54\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 7  Adaptive Sampling with Feature Selection section start time : 2022-03-02 02:21:54\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:21:55\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:24:00\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:24:00\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:26:44\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:26:44\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:31:15\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:31:16\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:35:57\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:35:58\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:39:01\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:39:02\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:42:46\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:42:47\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:45:01\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:45:02\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:48:47\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:48:47\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:53:13\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:53:14\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:55:38\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 8  Adaptive Sampling with Feature Selection section start time : 2022-03-02 02:55:39\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:55:39\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 02:58:23\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 02:58:23\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:02:07\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:02:08\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:06:50\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:06:50\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:09:53\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:09:54\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:14:33\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:14:34\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:17:55\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:17:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:20:09\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:20:10\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:23:16\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:23:17\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:25:43\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:25:44\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:28:43\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 9  Adaptive Sampling with Feature Selection section start time : 2022-03-02 03:28:44\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:28:44\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:32:34\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:32:35\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:37:18\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:37:18\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:40:54\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:40:55\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:45:53\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:45:54\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:49:04\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:49:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:56:20\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:56:22\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 03:58:11\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 03:58:12\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:01:24\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:01:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:03:47\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:03:48\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:07:09\"\n",
      "[1] 11\n",
      "[1] \"seed : 9   rep : 10  Adaptive Sampling with Feature Selection section start time : 2022-03-02 04:07:10\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:07:11\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:11:52\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:11:53\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:14:54\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:14:55\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:19:56\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:19:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:23:06\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:23:07\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:26:10\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:26:11\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:29:07\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:29:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:32:15\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:32:16\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:35:03\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:35:04\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:40:31\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-03-02 04:40:32\"\n",
      "[1] \"ABM train_candidate run end time : 2022-03-02 04:42:06\"\n",
      "[1] 11\n"
     ]
    }
   ],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            set.seed(9) ### KONTROL\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                        \n",
    "                        set.seed(9) ### KONTROL\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                        \n",
    "                        fwrite(data.table(iter,new_oob_error = new_oob,oob_error = obb_err,seed = i,rep = r)\n",
    "                               ,paste0(outputs.path,sample.folder,model.type,\"_\",\"new_oob_error_\",sample.type,\".csv\"),append = TRUE)\n",
    "        \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30563d",
   "metadata": {},
   "source": [
    "## Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92aeb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0949b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
