{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc46849",
   "metadata": {},
   "source": [
    "## Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bef016",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Registered S3 method overwritten by 'rvest':\n",
      "  method            from\n",
      "  read_xml.response xml2\n",
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.1     ✔ purrr   0.3.2\n",
      "✔ tibble  3.1.0     ✔ dplyr   1.0.5\n",
      "✔ tidyr   1.1.3     ✔ stringr 1.4.0\n",
      "✔ readr   1.3.1     ✔ forcats 0.4.0\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘tidyr’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.6.3”── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::between()   masks data.table::between()\n",
      "✖ dplyr::filter()    masks stats::filter()\n",
      "✖ dplyr::first()     masks data.table::first()\n",
      "✖ dplyr::lag()       masks stats::lag()\n",
      "✖ dplyr::last()      masks data.table::last()\n",
      "✖ purrr::transpose() masks data.table::transpose()\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    as_data_frame, groups, union\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    compose, simplify\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    crossing\n",
      "\n",
      "The following object is masked from ‘package:tibble’:\n",
      "\n",
      "    as_data_frame\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Warning message:\n",
      "“package ‘lhs’ was built under R version 3.6.3”"
     ]
    }
   ],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "library(lhs)\n",
    "\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a098a0d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "The following object is masked from ‘package:igraph’:\n",
      "\n",
      "    groups\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "“package ‘factoextra’ was built under R version 3.6.3”Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n",
      "Loading required package: gridExtra\n",
      "Warning message:\n",
      "“package ‘gridExtra’ was built under R version 3.6.3”\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "source(paste0(folder.path,\"ThesisSetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"info_cascade_update_TDP_JPF_2020\" #\"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"/Users/ecemnaz.yildiz/Documents/NetLogo 6.0.4/Java\"\n",
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4090a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = \"info_cascade_update\" ##ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "data.path = paste0(folder.path,\"data/\")\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V3_RFE_mtrymultip2_\",model.type,\"_\",Sys.Date())\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71034",
   "metadata": {},
   "source": [
    "## Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7e24",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f148b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters #### Set model parameters Number of replications for each\n",
    "#### instance\n",
    "nofrep = 30 #############################\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "\n",
    "    feature_names = c(\"ground-truth\",\"max_links\"\n",
    "                  ,\"evidence\",\"sc-bel-prop\"\n",
    "                  ,\"prop-likelihood\",\"p-h-given-c\"\n",
    "                  ,\"n_init_believers\",\"learning_rate\"\n",
    "                  ,\"con-threshold\",\"expertise_influence\") \n",
    "    feature_ranges = data.table(  feature   = feature_names\n",
    "                                , min_range = c(0, 2,   0,   0, 0, 0, 0,   0, 0, 0)\n",
    "                                , max_range = c(1, 500, 100, 5, 1, 1, 100, 1, 1, 1))\n",
    "\n",
    "# \n",
    "output_name = c(\"cl-prop-same\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "#mtry = 2\n",
    "mtry.multiplier = 2 # when 1, it is default, when 2, it is at most twice of defaults \n",
    "nperm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeeb6f",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ca5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "\n",
    "elimination.type = \"NRFE\" # or \"RFE\"\n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 9\n",
    "metarep = c(1:3)#c(1:10)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 30\n",
    "test_ins = 30 ##c(100,400)\n",
    "train_ins_oneshot = 30\n",
    "train_ins_Ad = 30 ##50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameter\n",
    "p = 0.8 # elimination proportion\n",
    "# h = 1\n",
    "oob_allowance = 0.1\n",
    "\n",
    "seed.focus = 0 ##c(1,2,3,4,5,6,7,8,9,20)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "\n",
    "# Decide on strategy:\n",
    "elimination_start_iter = 5\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c171d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "test_set = data.table()\n",
    "for( t in test_ins){\n",
    "    test_set.name= paste0(data.path,\"test_set\",\"_\",model.type,\"_\",t,\".csv\")\n",
    "    test_set_Sub <- fread(test_set.name)  \n",
    "    \n",
    "    test_set = rbind(test_set, data.table(size = t, test_set_Sub))\n",
    "    \n",
    "    #assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c33a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/latex": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test\\_set\\_info\\_cascade\\_update\\_30.csv'"
      ],
      "text/markdown": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/plain": [
       "[1] \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste0(data.path,\"test_set\",\"_\",model.type,\"_\",test_ins,\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee16ba11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9329e",
   "metadata": {},
   "source": [
    "## Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30fa50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,seed.focus,train_ins_Ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c9b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08345fa",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                    \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                    \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13da08d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"seed : 0  Adaptive Sampling with Feature Selection section start time : 2021-12-18 14:50:32\"\n",
      "[1] \"seed : 0   rep : 2  Adaptive Sampling with Feature Selection section start time : 2021-12-18 14:50:32\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 14:50:33\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 14:52:41\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 14:52:41\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 14:54:54\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 14:54:54\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:00:25\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 15:00:25\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:04:30\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 15:04:30\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:08:51\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 15:08:52\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:11:04\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 15:11:04\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:12:21\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2021-12-18 15:12:21\"\n",
      "[1] \"ABM train_candidate run end time : 2021-12-18 15:14:00\"\n",
      "[1] 9\n"
     ]
    }
   ],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "i = 0\n",
    "    \n",
    "    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "r = 2 \n",
    "        print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                fwrite(data.table(setcolorder(train_candidates, feature_names), \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_ABM_train_candidates_table_\"\n",
    "                       ,sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "\n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                    \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                    \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    \n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30563d",
   "metadata": {},
   "source": [
    "## Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0949b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
