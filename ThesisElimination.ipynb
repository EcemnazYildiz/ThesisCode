{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc46849",
   "metadata": {},
   "source": [
    "## Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bef016",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "library(lhs)\n",
    "\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a098a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "source(paste0(folder.path,\"ThesisSetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"info_cascade_update_TDP_JPF_2020\" #\"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"/Users/ecemnaz.yildiz/Documents/NetLogo 6.0.4/Java\"\n",
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = \"info_cascade_update\" ##ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "\n",
    "training_set_size = 500 #75 #500\n",
    "training_set_seed = 9\n",
    "training_set_date = \"2022-02-13\"\n",
    "\n",
    "test_set_size = 215 #30 #215\n",
    "test_set_seed = 8\n",
    "test_set_date = \"2022-02-12\"\n",
    "\n",
    "data.path = paste0(folder.path,\"Data_\",training_set_size,\"_Seed\",training_set_seed,\"/\")\n",
    "\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V3_RFE_mtrymultip2_\",model.type,\"_\",Sys.Date(),\"_\",format(Sys.time(), \"%H.%M\"),\"_\",training_set_size,\"_\",training_set_seed)\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71034",
   "metadata": {},
   "source": [
    "## Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7e24",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f148b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters #### Set model parameters Number of replications for each\n",
    "#### instance\n",
    "nofrep = 30 #############################\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "\n",
    "    feature_names = c(\n",
    "    \"max_links\",\n",
    "    \"evidence\",\n",
    "    \"sc-bel-prop\",\n",
    "    \"prop-likelihood\",\n",
    "    \"n_init_believers\",\n",
    "    \"prior-mean\",\n",
    "    \"prior-sd\",\n",
    "    \"expertise_influence\") \n",
    "    feature_ranges = data.table(  feature   = feature_names\n",
    "                                , min_range = c(2, 0, 0, 0, 0, 0, 0, 0)\n",
    "                                , max_range = c(500, 100, 5, 1, 100, 1, 1, 1)\n",
    "                               )\n",
    "\n",
    "# \n",
    "output_name = c(\"cl-prop-same\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "#mtry = 2\n",
    "mtry.multiplier = 2 # when 1, it is default, when 2, it is at most twice of defaults \n",
    "nperm = 5\n",
    "\n",
    "feature_importance_threshold = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeeb6f",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ca5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "\n",
    "elimination.type = \"NRFE\" # or \"RFE\"\n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 11\n",
    "metarep = c(1:10)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 30\n",
    "test_ins = 215 #30 #215 ##c(100,400)\n",
    "train_ins_oneshot = 500 #75 #500\n",
    "train_ins_Ad = 500 #75 #500 ##50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameter\n",
    "p = 0.5 # elimination proportion\n",
    "# h = 1\n",
    "oob_allowance = 0.5#0.1 #0.01\n",
    "\n",
    "seed.focus = 9 ##c(1,2,3,4,5,6,7,8,9,20)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "\n",
    "# Decide on strategy:\n",
    "elimination_start_iter = 5 #8 #6 #7 #2 #3 #4 #5\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c171d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbe6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "test_set = data.table()\n",
    "for( t in test_set_size){\n",
    "    test_set.name= paste0(data.path,\"test_set_\",model.type,\"_\",t,\"_seed\",test_set_seed,\"_\",test_set_date,\".csv\")\n",
    "    test_set_Sub <- fread(test_set.name)  \n",
    "    \n",
    "    test_set = rbind(test_set, data.table(size = t, test_set_Sub))\n",
    "    \n",
    "    #assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9329e",
   "metadata": {},
   "source": [
    "## Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30fa50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,training_set_seed,training_set_size,training_set_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08345fa",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            set.seed(seed.focus) ### KONTROL\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                        \n",
    "                        set.seed(seed.focus) ### KONTROL\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                        \n",
    "                        fwrite(data.table(iter,new_oob_error = new_oob,oob_error = obb_err,seed = i,rep = r)\n",
    "                               ,paste0(outputs.path,sample.folder,model.type,\"_\",\"new_oob_error_\",sample.type,\".csv\"),append = TRUE)\n",
    "        \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33963ee",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel - simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c292f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ \n",
    "    #print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ \n",
    "        #print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            #print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            set.seed(9) ### KONTROL\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                #print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                #print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                ########################################  TRY FEATURE IMPORTANCE #################################\n",
    "                    feature_importance <- importance(model_Sub, type = 1, scale = FALSE)\n",
    "                    range <- 1:nrow(feature_importance)\n",
    "                    run_step_log_entry(\"Elimination Procedure Start.\")\n",
    "                    planned_columns_left <- vector()\n",
    "                    candidate_eliminated_columns <- vector()\n",
    "                    run_step_log_entry(paste0(feature_importance)) #To record importance of each feature in current model.\n",
    "                    for(j in range){\n",
    "                        run_step_log_entry(paste0(\"For loop step number: \", j))\n",
    "                        \n",
    "                        if(feature_importance[j,] >= feature_importance_threshold){\n",
    "                            run_step_log_entry(paste0(\"Keep:\"  ,rownames(feature_importance)[j]))\n",
    "                            run_step_log_entry(paste0(\"Importance: \" ,feature_importance[j,]))\n",
    "                            planned_columns_left <- rbind(planned_columns_left,(rownames(feature_importance)[j]))\n",
    "                        }\n",
    "                        else{\n",
    "                            run_step_log_entry(paste0(\"Eliminate: \", rownames(feature_importance)[j]))\n",
    "                            candidate_eliminated_columns <- rbind(candidate_eliminated_columns,(rownames(feature_importance)[j]))\n",
    "                        }\n",
    "                    }\n",
    "\n",
    "                    if(nrow(planned_columns_left) < nrow(feature_importance)){\n",
    "                        run_step_log_entry(\"Approve Elimination.\")\n",
    "                        run_step_log_entry(paste0(\"All Features: \", nrow(feature_importance)))\n",
    "                        run_step_log_entry(paste0(\"Features Left: \",nrow(planned_columns_left)))                        \n",
    "                        apply_elim = TRUE\n",
    "                    }\n",
    "                    else{\n",
    "                        run_step_log_entry(\"Reject Elimination.\")\n",
    "                        #iter <- iteration_budget\n",
    "                        apply_elim <- FALSE\n",
    "                    }\n",
    "                                \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                                \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  rbind(eliminated_columns,candidate_eliminated_columns)   # rbind edilmeli\n",
    "\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30563d",
   "metadata": {},
   "source": [
    "## Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf9b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessionInfo()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
