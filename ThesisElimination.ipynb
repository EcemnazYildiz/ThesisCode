{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc46849",
   "metadata": {},
   "source": [
    "## Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bef016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Registered S3 method overwritten by 'rvest':\n",
      "  method            from\n",
      "  read_xml.response xml2\n",
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.1     ✔ purrr   0.3.2\n",
      "✔ tibble  3.1.0     ✔ dplyr   1.0.5\n",
      "✔ tidyr   1.1.3     ✔ stringr 1.4.0\n",
      "✔ readr   1.3.1     ✔ forcats 0.4.0\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘tidyr’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.6.3”── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::between()   masks data.table::between()\n",
      "✖ dplyr::filter()    masks stats::filter()\n",
      "✖ dplyr::first()     masks data.table::first()\n",
      "✖ dplyr::lag()       masks stats::lag()\n",
      "✖ dplyr::last()      masks data.table::last()\n",
      "✖ purrr::transpose() masks data.table::transpose()\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    as_data_frame, groups, union\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    compose, simplify\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    crossing\n",
      "\n",
      "The following object is masked from ‘package:tibble’:\n",
      "\n",
      "    as_data_frame\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Warning message:\n",
      "“package ‘lhs’ was built under R version 3.6.3”"
     ]
    }
   ],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "library(lhs)\n",
    "\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a098a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "The following object is masked from ‘package:igraph’:\n",
      "\n",
      "    groups\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "“package ‘factoextra’ was built under R version 3.6.3”Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n",
      "Loading required package: gridExtra\n",
      "Warning message:\n",
      "“package ‘gridExtra’ was built under R version 3.6.3”\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "source(paste0(folder.path,\"ThesisSetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"info_cascade_update_TDP_JPF_2020\" #\"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"/Users/ecemnaz.yildiz/Documents/NetLogo 6.0.4/Java\"\n",
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4090a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = \"info_cascade_update\" ##ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "data.path = paste0(folder.path,\"data/\")\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V3_RFE_mtrymultip2_\",model.type,\"_\",Sys.Date())\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71034",
   "metadata": {},
   "source": [
    "## Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7e24",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f148b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters #### Set model parameters Number of replications for each\n",
    "#### instance\n",
    "nofrep = 30 #############################\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "\n",
    "    feature_names = c(\"ground-truth\",\"max_links\"\n",
    "                  ,\"evidence\",\"sc-bel-prop\"\n",
    "                  ,\"prop-likelihood\",\"p-h-given-c\"\n",
    "                  ,\"n_init_believers\",\"learning_rate\"\n",
    "                  ,\"con-threshold\",\"expertise_influence\") \n",
    "    feature_ranges = data.table(  feature   = feature_names\n",
    "                                , min_range = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0)\n",
    "                                , max_range = c(1, 500, 100, 5, 1, 1, 100, 1, 1, 1))\n",
    "\n",
    "# \n",
    "output_name = c(\"cl-prop-same\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "#mtry = 2\n",
    "mtry.multiplier = 2 # when 1, it is default, when 2, it is at most twice of defaults \n",
    "nperm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeeb6f",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ca5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "\n",
    "elimination.type = \"NRFE\" # or \"RFE\"\n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 9\n",
    "metarep = c(1:3)#c(1:10)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 30\n",
    "test_ins = 30 ##c(100,400)\n",
    "train_ins_oneshot = 30\n",
    "train_ins_Ad = 30 ##50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameter\n",
    "p = 0.8 # elimination proportion\n",
    "# h = 1\n",
    "oob_allowance = 0.1\n",
    "\n",
    "seed.focus = 0 ##c(1,2,3,4,5,6,7,8,9,20)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "\n",
    "# Decide on strategy:\n",
    "elimination_start_iter = 5\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c171d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "test_set = data.table()\n",
    "for( t in test_ins){\n",
    "    test_set.name= paste0(data.path,\"test_set\",\"_\",model.type,\"_\",t,\".csv\")\n",
    "    test_set_Sub <- fread(test_set.name)  \n",
    "    \n",
    "    test_set = rbind(test_set, data.table(size = t, test_set_Sub))\n",
    "    \n",
    "    #assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c33a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/latex": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test\\_set\\_info\\_cascade\\_update\\_30.csv'"
      ],
      "text/markdown": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/plain": [
       "[1] \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste0(data.path,\"test_set\",\"_\",model.type,\"_\",test_ins,\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9329e",
   "metadata": {},
   "source": [
    "## Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30fa50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,seed.focus,train_ins_Ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "149c9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>ground-truth</th><th scope=col>max_links</th><th scope=col>evidence</th><th scope=col>sc-bel-prop</th><th scope=col>prop-likelihood</th><th scope=col>p-h-given-c</th><th scope=col>n_init_believers</th><th scope=col>learning_rate</th><th scope=col>con-threshold</th><th scope=col>expertise_influence</th><th scope=col>output</th><th scope=col>seed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>0.47601769 </td><td>309.80882  </td><td>83.549839  </td><td>2.68861870 </td><td>0.65168982 </td><td>0.63354368 </td><td>57.8611225 </td><td>0.54632148 </td><td>0.32160454 </td><td>0.541202792</td><td>44.91015   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.35672834 </td><td>317.30518  </td><td>63.106664  </td><td>2.22335191 </td><td>0.90763209 </td><td>0.56252703 </td><td>76.1547683 </td><td>0.47592333 </td><td>0.46328014 </td><td>0.524350752</td><td>43.35827   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.71638853 </td><td> 80.00353  </td><td>58.991850  </td><td>2.40930323 </td><td>0.68969464 </td><td>0.74683716 </td><td>43.1984348 </td><td>0.50098188 </td><td>0.38406676 </td><td>0.475940387</td><td>46.13721   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.38894489 </td><td>268.21950  </td><td>83.062600  </td><td>3.66248914 </td><td>0.62880975 </td><td>0.60311785 </td><td>34.5217967 </td><td>0.23294625 </td><td>0.70413467 </td><td>0.239238373</td><td>46.87023   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.50152214 </td><td>376.17234  </td><td>68.169001  </td><td>2.96416124 </td><td>0.50981017 </td><td>0.86337559 </td><td>16.2605515 </td><td>0.77409926 </td><td>0.60234462 </td><td>0.610609240</td><td>48.47599   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.40541209 </td><td>263.49302  </td><td>47.911606  </td><td>1.78630814 </td><td>0.26884695 </td><td>0.45373039 </td><td>77.0902000 </td><td>0.60907955 </td><td>0.67106358 </td><td>0.441360433</td><td>43.27983   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.44819153 </td><td> 86.80230  </td><td>95.770899  </td><td>3.07717965 </td><td>0.46432791 </td><td>0.26671911 </td><td>96.6376782 </td><td>0.96163352 </td><td>0.80923608 </td><td>0.887869010</td><td>41.82674   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.53651635 </td><td>214.02388  </td><td>63.358828  </td><td>3.30239302 </td><td>0.18843268 </td><td>0.47324912 </td><td>90.6509697 </td><td>0.24464914 </td><td>0.13135634 </td><td>0.795441728</td><td>42.26746   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.07952148 </td><td>217.82492  </td><td>33.549733  </td><td>0.98303740 </td><td>0.78358728 </td><td>0.14660758 </td><td>31.4393862 </td><td>0.44938462 </td><td>0.48563582 </td><td>0.428534337</td><td>47.14763   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.24501809 </td><td> 50.51225  </td><td>74.346076  </td><td>1.62021644 </td><td>0.43220176 </td><td>0.89463243 </td><td>12.5805322 </td><td>0.34182141 </td><td>0.54708903 </td><td>0.205643966</td><td>51.20797   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.63856199 </td><td>459.48145  </td><td>53.224632  </td><td>4.40608682 </td><td>0.47381428 </td><td>0.25799465 </td><td>67.9886207 </td><td>0.68151506 </td><td>0.28799508 </td><td>0.320194715</td><td>44.07850   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.80488346 </td><td>354.04219  </td><td>46.331153  </td><td>0.37218905 </td><td>0.83127037 </td><td>0.95397055 </td><td>21.3105169 </td><td>0.19295557 </td><td>0.52876480 </td><td>0.730052653</td><td>48.02256   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.57630990 </td><td> 15.65373  </td><td>90.351600  </td><td>1.18339279 </td><td>0.54256842 </td><td>0.31927096 </td><td>19.1455078 </td><td>0.85751843 </td><td>0.14812456 </td><td>0.733731810</td><td>59.69117   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.77041118 </td><td>171.30952  </td><td>36.678126  </td><td>4.22830276 </td><td>0.72660916 </td><td>0.50263203 </td><td>44.2274257 </td><td>0.03241952 </td><td>0.25700116 </td><td>0.967152144</td><td>46.02098   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.14513135 </td><td>296.79148  </td><td> 2.711361  </td><td>1.83963641 </td><td>0.36661554 </td><td>0.33612344 </td><td>64.7271505 </td><td>0.87168179 </td><td>0.04355859 </td><td>0.190592471</td><td>44.30201   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.29182177 </td><td>403.67980  </td><td>70.859862  </td><td>3.69643211 </td><td>0.26371119 </td><td>0.42379335 </td><td>47.3906214 </td><td>0.31178857 </td><td>0.74889903 </td><td>0.841312388</td><td>45.74135   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.10346714 </td><td> 43.94761  </td><td>26.782110  </td><td>4.66349926 </td><td>0.58452664 </td><td>0.18292822 </td><td>85.1104706 </td><td>0.58659189 </td><td>0.59300508 </td><td>0.672293694</td><td>42.86651   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.98174934 </td><td>198.10849  </td><td>55.243804  </td><td>0.64423474 </td><td>0.10223249 </td><td>0.20594726 </td><td>72.3019701 </td><td>0.97725222 </td><td>0.79485901 </td><td>0.816627014</td><td>43.72011   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.03950368 </td><td>158.08886  </td><td>86.922408  </td><td>1.07490666 </td><td>0.09893722 </td><td>0.39887169 </td><td>25.3765003 </td><td>0.11726508 </td><td>0.02038889 </td><td>0.153329309</td><td>47.68389   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.85188611 </td><td>476.08661  </td><td>17.821875  </td><td>0.18955886 </td><td>0.95177300 </td><td>0.91359260 </td><td>50.0465866 </td><td>0.93145884 </td><td>0.64156264 </td><td>0.001923862</td><td>45.47320   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.67260541 </td><td>105.51007  </td><td>41.871069  </td><td>1.40523149 </td><td>0.76527629 </td><td>0.67846781 </td><td>82.7361302 </td><td>0.08154482 </td><td>0.98428638 </td><td>0.091779928</td><td>42.86634   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.19755468 </td><td>149.53917  </td><td> 3.911665  </td><td>3.98857254 </td><td>0.30140243 </td><td>0.81580866 </td><td> 3.5105931 </td><td>0.82436122 </td><td>0.21835248 </td><td>0.920309543</td><td>55.39434   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.94938161 </td><td>129.17010  </td><td>77.907751  </td><td>4.00984293 </td><td>0.39423793 </td><td>0.08744255 </td><td> 0.5524448 </td><td>0.41810701 </td><td>0.19107811 </td><td>0.296165683</td><td> 0.00000   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.60850101 </td><td>426.19315  </td><td>11.032080  </td><td>3.44727788 </td><td>0.22759002 </td><td>0.97908562 </td><td>99.7437568 </td><td>0.64141421 </td><td>0.93629280 </td><td>0.592873474</td><td>41.62802   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.03283095 </td><td>435.86283  </td><td> 9.179517  </td><td>4.74314211 </td><td>0.98971872 </td><td>0.03473545 </td><td>55.0380307 </td><td>0.38222864 </td><td>0.88022648 </td><td>0.109845465</td><td>45.07540   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.90598062 </td><td>499.15278  </td><td>15.687057  </td><td>2.03653188 </td><td>0.88119443 </td><td>0.02846176 </td><td>37.1724002 </td><td>0.72339159 </td><td>0.34528693 </td><td>0.939470711</td><td>46.58785   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.88081637 </td><td>347.04184  </td><td>31.592234  </td><td>0.68327497 </td><td>0.05928076 </td><td>0.57435605 </td><td>88.5115510 </td><td>0.13893367 </td><td>0.07742080 </td><td>0.049369550</td><td>42.43369   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.73852995 </td><td> 26.99856  </td><td>23.024449  </td><td>4.87827067 </td><td>0.03138657 </td><td>0.76840357 </td><td>27.4412562 </td><td>0.04733936 </td><td>0.83423326 </td><td>0.635451322</td><td>54.81774   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.21712107 </td><td>391.46709  </td><td>26.035756  </td><td>0.09091459 </td><td>0.16354992 </td><td>0.11234408 </td><td> 9.4471089 </td><td>0.29020407 </td><td>0.92921069 </td><td>0.352597127</td><td>49.16110   </td><td>0          </td></tr>\n",
       "\t<tr><td>0.30147697 </td><td>248.26575  </td><td>98.158734  </td><td>2.60679969 </td><td>0.85002898 </td><td>0.72525885 </td><td>61.7155555 </td><td>0.75383667 </td><td>0.40803055 </td><td>0.387801080</td><td>44.58299   </td><td>0          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       " ground-truth & max\\_links & evidence & sc-bel-prop & prop-likelihood & p-h-given-c & n\\_init\\_believers & learning\\_rate & con-threshold & expertise\\_influence & output & seed\\\\\n",
       "\\hline\n",
       "\t 0.47601769  & 309.80882   & 83.549839   & 2.68861870  & 0.65168982  & 0.63354368  & 57.8611225  & 0.54632148  & 0.32160454  & 0.541202792 & 44.91015    & 0          \\\\\n",
       "\t 0.35672834  & 317.30518   & 63.106664   & 2.22335191  & 0.90763209  & 0.56252703  & 76.1547683  & 0.47592333  & 0.46328014  & 0.524350752 & 43.35827    & 0          \\\\\n",
       "\t 0.71638853  &  80.00353   & 58.991850   & 2.40930323  & 0.68969464  & 0.74683716  & 43.1984348  & 0.50098188  & 0.38406676  & 0.475940387 & 46.13721    & 0          \\\\\n",
       "\t 0.38894489  & 268.21950   & 83.062600   & 3.66248914  & 0.62880975  & 0.60311785  & 34.5217967  & 0.23294625  & 0.70413467  & 0.239238373 & 46.87023    & 0          \\\\\n",
       "\t 0.50152214  & 376.17234   & 68.169001   & 2.96416124  & 0.50981017  & 0.86337559  & 16.2605515  & 0.77409926  & 0.60234462  & 0.610609240 & 48.47599    & 0          \\\\\n",
       "\t 0.40541209  & 263.49302   & 47.911606   & 1.78630814  & 0.26884695  & 0.45373039  & 77.0902000  & 0.60907955  & 0.67106358  & 0.441360433 & 43.27983    & 0          \\\\\n",
       "\t 0.44819153  &  86.80230   & 95.770899   & 3.07717965  & 0.46432791  & 0.26671911  & 96.6376782  & 0.96163352  & 0.80923608  & 0.887869010 & 41.82674    & 0          \\\\\n",
       "\t 0.53651635  & 214.02388   & 63.358828   & 3.30239302  & 0.18843268  & 0.47324912  & 90.6509697  & 0.24464914  & 0.13135634  & 0.795441728 & 42.26746    & 0          \\\\\n",
       "\t 0.07952148  & 217.82492   & 33.549733   & 0.98303740  & 0.78358728  & 0.14660758  & 31.4393862  & 0.44938462  & 0.48563582  & 0.428534337 & 47.14763    & 0          \\\\\n",
       "\t 0.24501809  &  50.51225   & 74.346076   & 1.62021644  & 0.43220176  & 0.89463243  & 12.5805322  & 0.34182141  & 0.54708903  & 0.205643966 & 51.20797    & 0          \\\\\n",
       "\t 0.63856199  & 459.48145   & 53.224632   & 4.40608682  & 0.47381428  & 0.25799465  & 67.9886207  & 0.68151506  & 0.28799508  & 0.320194715 & 44.07850    & 0          \\\\\n",
       "\t 0.80488346  & 354.04219   & 46.331153   & 0.37218905  & 0.83127037  & 0.95397055  & 21.3105169  & 0.19295557  & 0.52876480  & 0.730052653 & 48.02256    & 0          \\\\\n",
       "\t 0.57630990  &  15.65373   & 90.351600   & 1.18339279  & 0.54256842  & 0.31927096  & 19.1455078  & 0.85751843  & 0.14812456  & 0.733731810 & 59.69117    & 0          \\\\\n",
       "\t 0.77041118  & 171.30952   & 36.678126   & 4.22830276  & 0.72660916  & 0.50263203  & 44.2274257  & 0.03241952  & 0.25700116  & 0.967152144 & 46.02098    & 0          \\\\\n",
       "\t 0.14513135  & 296.79148   &  2.711361   & 1.83963641  & 0.36661554  & 0.33612344  & 64.7271505  & 0.87168179  & 0.04355859  & 0.190592471 & 44.30201    & 0          \\\\\n",
       "\t 0.29182177  & 403.67980   & 70.859862   & 3.69643211  & 0.26371119  & 0.42379335  & 47.3906214  & 0.31178857  & 0.74889903  & 0.841312388 & 45.74135    & 0          \\\\\n",
       "\t 0.10346714  &  43.94761   & 26.782110   & 4.66349926  & 0.58452664  & 0.18292822  & 85.1104706  & 0.58659189  & 0.59300508  & 0.672293694 & 42.86651    & 0          \\\\\n",
       "\t 0.98174934  & 198.10849   & 55.243804   & 0.64423474  & 0.10223249  & 0.20594726  & 72.3019701  & 0.97725222  & 0.79485901  & 0.816627014 & 43.72011    & 0          \\\\\n",
       "\t 0.03950368  & 158.08886   & 86.922408   & 1.07490666  & 0.09893722  & 0.39887169  & 25.3765003  & 0.11726508  & 0.02038889  & 0.153329309 & 47.68389    & 0          \\\\\n",
       "\t 0.85188611  & 476.08661   & 17.821875   & 0.18955886  & 0.95177300  & 0.91359260  & 50.0465866  & 0.93145884  & 0.64156264  & 0.001923862 & 45.47320    & 0          \\\\\n",
       "\t 0.67260541  & 105.51007   & 41.871069   & 1.40523149  & 0.76527629  & 0.67846781  & 82.7361302  & 0.08154482  & 0.98428638  & 0.091779928 & 42.86634    & 0          \\\\\n",
       "\t 0.19755468  & 149.53917   &  3.911665   & 3.98857254  & 0.30140243  & 0.81580866  &  3.5105931  & 0.82436122  & 0.21835248  & 0.920309543 & 55.39434    & 0          \\\\\n",
       "\t 0.94938161  & 129.17010   & 77.907751   & 4.00984293  & 0.39423793  & 0.08744255  &  0.5524448  & 0.41810701  & 0.19107811  & 0.296165683 &  0.00000    & 0          \\\\\n",
       "\t 0.60850101  & 426.19315   & 11.032080   & 3.44727788  & 0.22759002  & 0.97908562  & 99.7437568  & 0.64141421  & 0.93629280  & 0.592873474 & 41.62802    & 0          \\\\\n",
       "\t 0.03283095  & 435.86283   &  9.179517   & 4.74314211  & 0.98971872  & 0.03473545  & 55.0380307  & 0.38222864  & 0.88022648  & 0.109845465 & 45.07540    & 0          \\\\\n",
       "\t 0.90598062  & 499.15278   & 15.687057   & 2.03653188  & 0.88119443  & 0.02846176  & 37.1724002  & 0.72339159  & 0.34528693  & 0.939470711 & 46.58785    & 0          \\\\\n",
       "\t 0.88081637  & 347.04184   & 31.592234   & 0.68327497  & 0.05928076  & 0.57435605  & 88.5115510  & 0.13893367  & 0.07742080  & 0.049369550 & 42.43369    & 0          \\\\\n",
       "\t 0.73852995  &  26.99856   & 23.024449   & 4.87827067  & 0.03138657  & 0.76840357  & 27.4412562  & 0.04733936  & 0.83423326  & 0.635451322 & 54.81774    & 0          \\\\\n",
       "\t 0.21712107  & 391.46709   & 26.035756   & 0.09091459  & 0.16354992  & 0.11234408  &  9.4471089  & 0.29020407  & 0.92921069  & 0.352597127 & 49.16110    & 0          \\\\\n",
       "\t 0.30147697  & 248.26575   & 98.158734   & 2.60679969  & 0.85002898  & 0.72525885  & 61.7155555  & 0.75383667  & 0.40803055  & 0.387801080 & 44.58299    & 0          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| ground-truth | max_links | evidence | sc-bel-prop | prop-likelihood | p-h-given-c | n_init_believers | learning_rate | con-threshold | expertise_influence | output | seed |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 0.47601769  | 309.80882   | 83.549839   | 2.68861870  | 0.65168982  | 0.63354368  | 57.8611225  | 0.54632148  | 0.32160454  | 0.541202792 | 44.91015    | 0           |\n",
       "| 0.35672834  | 317.30518   | 63.106664   | 2.22335191  | 0.90763209  | 0.56252703  | 76.1547683  | 0.47592333  | 0.46328014  | 0.524350752 | 43.35827    | 0           |\n",
       "| 0.71638853  |  80.00353   | 58.991850   | 2.40930323  | 0.68969464  | 0.74683716  | 43.1984348  | 0.50098188  | 0.38406676  | 0.475940387 | 46.13721    | 0           |\n",
       "| 0.38894489  | 268.21950   | 83.062600   | 3.66248914  | 0.62880975  | 0.60311785  | 34.5217967  | 0.23294625  | 0.70413467  | 0.239238373 | 46.87023    | 0           |\n",
       "| 0.50152214  | 376.17234   | 68.169001   | 2.96416124  | 0.50981017  | 0.86337559  | 16.2605515  | 0.77409926  | 0.60234462  | 0.610609240 | 48.47599    | 0           |\n",
       "| 0.40541209  | 263.49302   | 47.911606   | 1.78630814  | 0.26884695  | 0.45373039  | 77.0902000  | 0.60907955  | 0.67106358  | 0.441360433 | 43.27983    | 0           |\n",
       "| 0.44819153  |  86.80230   | 95.770899   | 3.07717965  | 0.46432791  | 0.26671911  | 96.6376782  | 0.96163352  | 0.80923608  | 0.887869010 | 41.82674    | 0           |\n",
       "| 0.53651635  | 214.02388   | 63.358828   | 3.30239302  | 0.18843268  | 0.47324912  | 90.6509697  | 0.24464914  | 0.13135634  | 0.795441728 | 42.26746    | 0           |\n",
       "| 0.07952148  | 217.82492   | 33.549733   | 0.98303740  | 0.78358728  | 0.14660758  | 31.4393862  | 0.44938462  | 0.48563582  | 0.428534337 | 47.14763    | 0           |\n",
       "| 0.24501809  |  50.51225   | 74.346076   | 1.62021644  | 0.43220176  | 0.89463243  | 12.5805322  | 0.34182141  | 0.54708903  | 0.205643966 | 51.20797    | 0           |\n",
       "| 0.63856199  | 459.48145   | 53.224632   | 4.40608682  | 0.47381428  | 0.25799465  | 67.9886207  | 0.68151506  | 0.28799508  | 0.320194715 | 44.07850    | 0           |\n",
       "| 0.80488346  | 354.04219   | 46.331153   | 0.37218905  | 0.83127037  | 0.95397055  | 21.3105169  | 0.19295557  | 0.52876480  | 0.730052653 | 48.02256    | 0           |\n",
       "| 0.57630990  |  15.65373   | 90.351600   | 1.18339279  | 0.54256842  | 0.31927096  | 19.1455078  | 0.85751843  | 0.14812456  | 0.733731810 | 59.69117    | 0           |\n",
       "| 0.77041118  | 171.30952   | 36.678126   | 4.22830276  | 0.72660916  | 0.50263203  | 44.2274257  | 0.03241952  | 0.25700116  | 0.967152144 | 46.02098    | 0           |\n",
       "| 0.14513135  | 296.79148   |  2.711361   | 1.83963641  | 0.36661554  | 0.33612344  | 64.7271505  | 0.87168179  | 0.04355859  | 0.190592471 | 44.30201    | 0           |\n",
       "| 0.29182177  | 403.67980   | 70.859862   | 3.69643211  | 0.26371119  | 0.42379335  | 47.3906214  | 0.31178857  | 0.74889903  | 0.841312388 | 45.74135    | 0           |\n",
       "| 0.10346714  |  43.94761   | 26.782110   | 4.66349926  | 0.58452664  | 0.18292822  | 85.1104706  | 0.58659189  | 0.59300508  | 0.672293694 | 42.86651    | 0           |\n",
       "| 0.98174934  | 198.10849   | 55.243804   | 0.64423474  | 0.10223249  | 0.20594726  | 72.3019701  | 0.97725222  | 0.79485901  | 0.816627014 | 43.72011    | 0           |\n",
       "| 0.03950368  | 158.08886   | 86.922408   | 1.07490666  | 0.09893722  | 0.39887169  | 25.3765003  | 0.11726508  | 0.02038889  | 0.153329309 | 47.68389    | 0           |\n",
       "| 0.85188611  | 476.08661   | 17.821875   | 0.18955886  | 0.95177300  | 0.91359260  | 50.0465866  | 0.93145884  | 0.64156264  | 0.001923862 | 45.47320    | 0           |\n",
       "| 0.67260541  | 105.51007   | 41.871069   | 1.40523149  | 0.76527629  | 0.67846781  | 82.7361302  | 0.08154482  | 0.98428638  | 0.091779928 | 42.86634    | 0           |\n",
       "| 0.19755468  | 149.53917   |  3.911665   | 3.98857254  | 0.30140243  | 0.81580866  |  3.5105931  | 0.82436122  | 0.21835248  | 0.920309543 | 55.39434    | 0           |\n",
       "| 0.94938161  | 129.17010   | 77.907751   | 4.00984293  | 0.39423793  | 0.08744255  |  0.5524448  | 0.41810701  | 0.19107811  | 0.296165683 |  0.00000    | 0           |\n",
       "| 0.60850101  | 426.19315   | 11.032080   | 3.44727788  | 0.22759002  | 0.97908562  | 99.7437568  | 0.64141421  | 0.93629280  | 0.592873474 | 41.62802    | 0           |\n",
       "| 0.03283095  | 435.86283   |  9.179517   | 4.74314211  | 0.98971872  | 0.03473545  | 55.0380307  | 0.38222864  | 0.88022648  | 0.109845465 | 45.07540    | 0           |\n",
       "| 0.90598062  | 499.15278   | 15.687057   | 2.03653188  | 0.88119443  | 0.02846176  | 37.1724002  | 0.72339159  | 0.34528693  | 0.939470711 | 46.58785    | 0           |\n",
       "| 0.88081637  | 347.04184   | 31.592234   | 0.68327497  | 0.05928076  | 0.57435605  | 88.5115510  | 0.13893367  | 0.07742080  | 0.049369550 | 42.43369    | 0           |\n",
       "| 0.73852995  |  26.99856   | 23.024449   | 4.87827067  | 0.03138657  | 0.76840357  | 27.4412562  | 0.04733936  | 0.83423326  | 0.635451322 | 54.81774    | 0           |\n",
       "| 0.21712107  | 391.46709   | 26.035756   | 0.09091459  | 0.16354992  | 0.11234408  |  9.4471089  | 0.29020407  | 0.92921069  | 0.352597127 | 49.16110    | 0           |\n",
       "| 0.30147697  | 248.26575   | 98.158734   | 2.60679969  | 0.85002898  | 0.72525885  | 61.7155555  | 0.75383667  | 0.40803055  | 0.387801080 | 44.58299    | 0           |\n",
       "\n"
      ],
      "text/plain": [
       "   ground-truth max_links evidence  sc-bel-prop prop-likelihood p-h-given-c\n",
       "1  0.47601769   309.80882 83.549839 2.68861870  0.65168982      0.63354368 \n",
       "2  0.35672834   317.30518 63.106664 2.22335191  0.90763209      0.56252703 \n",
       "3  0.71638853    80.00353 58.991850 2.40930323  0.68969464      0.74683716 \n",
       "4  0.38894489   268.21950 83.062600 3.66248914  0.62880975      0.60311785 \n",
       "5  0.50152214   376.17234 68.169001 2.96416124  0.50981017      0.86337559 \n",
       "6  0.40541209   263.49302 47.911606 1.78630814  0.26884695      0.45373039 \n",
       "7  0.44819153    86.80230 95.770899 3.07717965  0.46432791      0.26671911 \n",
       "8  0.53651635   214.02388 63.358828 3.30239302  0.18843268      0.47324912 \n",
       "9  0.07952148   217.82492 33.549733 0.98303740  0.78358728      0.14660758 \n",
       "10 0.24501809    50.51225 74.346076 1.62021644  0.43220176      0.89463243 \n",
       "11 0.63856199   459.48145 53.224632 4.40608682  0.47381428      0.25799465 \n",
       "12 0.80488346   354.04219 46.331153 0.37218905  0.83127037      0.95397055 \n",
       "13 0.57630990    15.65373 90.351600 1.18339279  0.54256842      0.31927096 \n",
       "14 0.77041118   171.30952 36.678126 4.22830276  0.72660916      0.50263203 \n",
       "15 0.14513135   296.79148  2.711361 1.83963641  0.36661554      0.33612344 \n",
       "16 0.29182177   403.67980 70.859862 3.69643211  0.26371119      0.42379335 \n",
       "17 0.10346714    43.94761 26.782110 4.66349926  0.58452664      0.18292822 \n",
       "18 0.98174934   198.10849 55.243804 0.64423474  0.10223249      0.20594726 \n",
       "19 0.03950368   158.08886 86.922408 1.07490666  0.09893722      0.39887169 \n",
       "20 0.85188611   476.08661 17.821875 0.18955886  0.95177300      0.91359260 \n",
       "21 0.67260541   105.51007 41.871069 1.40523149  0.76527629      0.67846781 \n",
       "22 0.19755468   149.53917  3.911665 3.98857254  0.30140243      0.81580866 \n",
       "23 0.94938161   129.17010 77.907751 4.00984293  0.39423793      0.08744255 \n",
       "24 0.60850101   426.19315 11.032080 3.44727788  0.22759002      0.97908562 \n",
       "25 0.03283095   435.86283  9.179517 4.74314211  0.98971872      0.03473545 \n",
       "26 0.90598062   499.15278 15.687057 2.03653188  0.88119443      0.02846176 \n",
       "27 0.88081637   347.04184 31.592234 0.68327497  0.05928076      0.57435605 \n",
       "28 0.73852995    26.99856 23.024449 4.87827067  0.03138657      0.76840357 \n",
       "29 0.21712107   391.46709 26.035756 0.09091459  0.16354992      0.11234408 \n",
       "30 0.30147697   248.26575 98.158734 2.60679969  0.85002898      0.72525885 \n",
       "   n_init_believers learning_rate con-threshold expertise_influence output  \n",
       "1  57.8611225       0.54632148    0.32160454    0.541202792         44.91015\n",
       "2  76.1547683       0.47592333    0.46328014    0.524350752         43.35827\n",
       "3  43.1984348       0.50098188    0.38406676    0.475940387         46.13721\n",
       "4  34.5217967       0.23294625    0.70413467    0.239238373         46.87023\n",
       "5  16.2605515       0.77409926    0.60234462    0.610609240         48.47599\n",
       "6  77.0902000       0.60907955    0.67106358    0.441360433         43.27983\n",
       "7  96.6376782       0.96163352    0.80923608    0.887869010         41.82674\n",
       "8  90.6509697       0.24464914    0.13135634    0.795441728         42.26746\n",
       "9  31.4393862       0.44938462    0.48563582    0.428534337         47.14763\n",
       "10 12.5805322       0.34182141    0.54708903    0.205643966         51.20797\n",
       "11 67.9886207       0.68151506    0.28799508    0.320194715         44.07850\n",
       "12 21.3105169       0.19295557    0.52876480    0.730052653         48.02256\n",
       "13 19.1455078       0.85751843    0.14812456    0.733731810         59.69117\n",
       "14 44.2274257       0.03241952    0.25700116    0.967152144         46.02098\n",
       "15 64.7271505       0.87168179    0.04355859    0.190592471         44.30201\n",
       "16 47.3906214       0.31178857    0.74889903    0.841312388         45.74135\n",
       "17 85.1104706       0.58659189    0.59300508    0.672293694         42.86651\n",
       "18 72.3019701       0.97725222    0.79485901    0.816627014         43.72011\n",
       "19 25.3765003       0.11726508    0.02038889    0.153329309         47.68389\n",
       "20 50.0465866       0.93145884    0.64156264    0.001923862         45.47320\n",
       "21 82.7361302       0.08154482    0.98428638    0.091779928         42.86634\n",
       "22  3.5105931       0.82436122    0.21835248    0.920309543         55.39434\n",
       "23  0.5524448       0.41810701    0.19107811    0.296165683          0.00000\n",
       "24 99.7437568       0.64141421    0.93629280    0.592873474         41.62802\n",
       "25 55.0380307       0.38222864    0.88022648    0.109845465         45.07540\n",
       "26 37.1724002       0.72339159    0.34528693    0.939470711         46.58785\n",
       "27 88.5115510       0.13893367    0.07742080    0.049369550         42.43369\n",
       "28 27.4412562       0.04733936    0.83423326    0.635451322         54.81774\n",
       "29  9.4471089       0.29020407    0.92921069    0.352597127         49.16110\n",
       "30 61.7155555       0.75383667    0.40803055    0.387801080         44.58299\n",
       "   seed\n",
       "1  0   \n",
       "2  0   \n",
       "3  0   \n",
       "4  0   \n",
       "5  0   \n",
       "6  0   \n",
       "7  0   \n",
       "8  0   \n",
       "9  0   \n",
       "10 0   \n",
       "11 0   \n",
       "12 0   \n",
       "13 0   \n",
       "14 0   \n",
       "15 0   \n",
       "16 0   \n",
       "17 0   \n",
       "18 0   \n",
       "19 0   \n",
       "20 0   \n",
       "21 0   \n",
       "22 0   \n",
       "23 0   \n",
       "24 0   \n",
       "25 0   \n",
       "26 0   \n",
       "27 0   \n",
       "28 0   \n",
       "29 0   \n",
       "30 0   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaptive_initial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08345fa",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef3c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                        \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                    \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "                    \n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                    \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE\n",
    "                        } else {\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){     # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "            iter = iter + 1\n",
    "        }\n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30563d",
   "metadata": {},
   "source": [
    "## Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92aeb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
