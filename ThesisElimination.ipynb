{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cc46849",
   "metadata": {},
   "source": [
    "## Loading Packages & Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bef016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered S3 methods overwritten by 'ggplot2':\n",
      "  method         from \n",
      "  [.quosures     rlang\n",
      "  c.quosures     rlang\n",
      "  print.quosures rlang\n",
      "Registered S3 method overwritten by 'rvest':\n",
      "  method            from\n",
      "  read_xml.response xml2\n",
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ ggplot2 3.1.1     ✔ purrr   0.3.2\n",
      "✔ tibble  3.1.0     ✔ dplyr   1.0.5\n",
      "✔ tidyr   1.1.3     ✔ stringr 1.4.0\n",
      "✔ readr   1.3.1     ✔ forcats 0.4.0\n",
      "Warning message:\n",
      "“package ‘tibble’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘tidyr’ was built under R version 3.6.3”Warning message:\n",
      "“package ‘dplyr’ was built under R version 3.6.3”── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ dplyr::between()   masks data.table::between()\n",
      "✖ dplyr::filter()    masks stats::filter()\n",
      "✖ dplyr::first()     masks data.table::first()\n",
      "✖ dplyr::lag()       masks stats::lag()\n",
      "✖ dplyr::last()      masks data.table::last()\n",
      "✖ purrr::transpose() masks data.table::transpose()\n",
      "Loading required package: igraph\n",
      "\n",
      "Attaching package: ‘igraph’\n",
      "\n",
      "The following objects are masked from ‘package:dplyr’:\n",
      "\n",
      "    as_data_frame, groups, union\n",
      "\n",
      "The following objects are masked from ‘package:purrr’:\n",
      "\n",
      "    compose, simplify\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    crossing\n",
      "\n",
      "The following object is masked from ‘package:tibble’:\n",
      "\n",
      "    as_data_frame\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    decompose, spectrum\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    union\n",
      "\n",
      "Warning message:\n",
      "“package ‘lhs’ was built under R version 3.6.3”"
     ]
    }
   ],
   "source": [
    "rm(list=ls())\n",
    "\n",
    "library(data.table)\n",
    "library(tidyverse)\n",
    "library(rJava)\n",
    "library(RNetLogo)\n",
    "library(lhs)\n",
    "\n",
    "options(warn = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a098a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘plotly’\n",
      "\n",
      "The following object is masked from ‘package:igraph’:\n",
      "\n",
      "    groups\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    last_plot\n",
      "\n",
      "The following object is masked from ‘package:stats’:\n",
      "\n",
      "    filter\n",
      "\n",
      "The following object is masked from ‘package:graphics’:\n",
      "\n",
      "    layout\n",
      "\n",
      "Loading required package: lattice\n",
      "\n",
      "Attaching package: ‘caret’\n",
      "\n",
      "The following object is masked from ‘package:purrr’:\n",
      "\n",
      "    lift\n",
      "\n",
      "randomForest 4.6-14\n",
      "Type rfNews() to see new features/changes/bug fixes.\n",
      "\n",
      "Attaching package: ‘randomForest’\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:ggplot2’:\n",
      "\n",
      "    margin\n",
      "\n",
      "Warning message:\n",
      "“package ‘factoextra’ was built under R version 3.6.3”Welcome! Want to learn more? See two factoextra-related books at https://goo.gl/ve3WBa\n",
      "Loading required package: gridExtra\n",
      "Warning message:\n",
      "“package ‘gridExtra’ was built under R version 3.6.3”\n",
      "Attaching package: ‘gridExtra’\n",
      "\n",
      "The following object is masked from ‘package:randomForest’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    combine\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "source(paste0(folder.path,\"ThesisSetupCode.r\"))\n",
    "\n",
    "Is_Headless <- 1\n",
    "nl.model <- \"info_cascade_update_TDP_JPF_2020\" #\"Segregation_Dummy\"\n",
    "\n",
    "nl.path <- \"/Users/ecemnaz.yildiz/Documents/NetLogo 6.0.4/Java\"\n",
    "folder.path = \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/\"\n",
    "\n",
    "model.path <- paste0(folder.path, nl.model, \".nlogo\")\n",
    "\n",
    "if (Is_Headless == 0) {\n",
    "    NLStart(nl.path, gui = TRUE, nl.jarname = \"netlogo-6.0.4.jar\")\n",
    "    NLLoadModel(model.path)\n",
    "} else {\n",
    "    NLStart(nl.path, gui = FALSE, nl.jarname = \"netlogo-6.0.4.jar\", nl.obj = nl.model)\n",
    "    NLLoadModel(model.path, nl.obj = nl.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4090a44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.type = \"info_cascade_update\" ##ifelse(nl.model == \"Segregation\", \"basic\", \"dummy\")\n",
    "# the path of data folder\n",
    "data.path = paste0(folder.path,\"data/\")\n",
    "# the path for outputs to be record\n",
    "output.folder = paste0(\"outputs_V3_RFE_mtrymultip2_\",model.type,\"_\",Sys.Date())\n",
    "dir.create(file.path(folder.path, output.folder), showWarnings = FALSE)\n",
    "\n",
    "outputs.path = paste0(folder.path,output.folder,\"/\")\n",
    "\n",
    "# Read Me File to keep info about the output folder\n",
    "ReadMe = paste0(outputs.path,\"ReadMe_\",model.type,\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30f71034",
   "metadata": {},
   "source": [
    "## Model Parameters & Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddf7e24",
   "metadata": {},
   "source": [
    "### Set model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f148b089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model Parameters #### Set model parameters Number of replications for each\n",
    "#### instance\n",
    "nofrep = 30 #############################\n",
    "\n",
    "# order feature names according to their definition order in run_model\n",
    "\n",
    "    feature_names = c(\n",
    "    \"max_links\",\n",
    "    \"evidence\",\n",
    "    \"sc-bel-prop\",\n",
    "    \"prop-likelihood\",\n",
    "    \"n_init_believers\",\n",
    "    \"prior-mean\",\n",
    "    \"prior-sd\",\n",
    "    \"expertise_influence\") \n",
    "    feature_ranges = data.table(  feature   = feature_names\n",
    "                                , min_range = c(2, 0, 0, 0, 0, 0, 0, 0)\n",
    "                                , max_range = c(500, 100, 5, 1, 100, 1, 1, 1)\n",
    "                               )\n",
    "\n",
    "# \n",
    "output_name = c(\"cl-prop-same\")\n",
    "\n",
    "# Number of input parameters of the agent-based model\n",
    "nofparams = length(feature_names)\n",
    "\n",
    "# set RF parameters\n",
    "ntree = 300\n",
    "#mtry = 2\n",
    "mtry.multiplier = 2 # when 1, it is default, when 2, it is at most twice of defaults \n",
    "nperm = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2deeeb6f",
   "metadata": {},
   "source": [
    "### Set user parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60ca5d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### User parameters ####\n",
    "error_type = \"RMSE\"  # MAPE, BIAS\n",
    "\n",
    "# choose the uncertainty measure\n",
    "selection_metric <- \"coefvar\"  #, 'range' \n",
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "\n",
    "elimination.type = \"NRFE\" # or \"RFE\"\n",
    "\n",
    "# Number of iterations\n",
    "iteration_budget = 11\n",
    "metarep = c(1:10)\n",
    "\n",
    "# Number of instances\n",
    "unlabeled_ins = 30\n",
    "test_ins = 30 ##c(100,400)\n",
    "train_ins_oneshot = 30\n",
    "train_ins_Ad = 30 ##50\n",
    "\n",
    "# Set selection parameters\n",
    "selected_ins = 5  #nofinstancesWillbeSelected in each step\n",
    "\n",
    "# Set elimination parameter\n",
    "p = 0.8 # elimination proportion\n",
    "# h = 1\n",
    "oob_allowance = 0.1\n",
    "\n",
    "seed.focus = 8 ##c(1,2,3,4,5,6,7,8,9,20)\n",
    "\n",
    "## !!!\n",
    "unlabeled.type = \"refresh and ElimInducedSampling\"\n",
    "\n",
    "# Decide on strategy:\n",
    "elimination_start_iter = 5\n",
    "\n",
    "log_entry()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8c171d",
   "metadata": {},
   "source": [
    "## Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dbe6d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Test Sets ####\n",
    "test_set = data.table()\n",
    "for( t in test_ins){\n",
    "    test_set.name= paste0(data.path,\"test_set\",\"_\",model.type,\"_\",t,\".csv\")\n",
    "    test_set_Sub <- fread(test_set.name)  \n",
    "    \n",
    "    test_set = rbind(test_set, data.table(size = t, test_set_Sub))\n",
    "    \n",
    "    #assign(paste0(\"test_set_\",t),test_set)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c33a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/latex": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test\\_set\\_info\\_cascade\\_update\\_30.csv'"
      ],
      "text/markdown": [
       "'/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv'"
      ],
      "text/plain": [
       "[1] \"/Users/ecemnaz.yildiz/Documents/Personal/Thesis/data/test_set_info_cascade_update_30.csv\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste0(data.path,\"test_set\",\"_\",model.type,\"_\",test_ins,\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee16ba11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>size</th><th scope=col>max_links</th><th scope=col>evidence</th><th scope=col>sc-bel-prop</th><th scope=col>prop-likelihood</th><th scope=col>n_init_believers</th><th scope=col>prior-mean</th><th scope=col>prior-sd</th><th scope=col>expertise_influence</th><th scope=col>output</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>30         </td><td>153.52986  </td><td>17.822423  </td><td>3.5235470  </td><td>0.99942973 </td><td>21.415365  </td><td>0.31318558 </td><td>0.73333450 </td><td>0.388069845</td><td>48.10765   </td></tr>\n",
       "\t<tr><td>30         </td><td>238.41998  </td><td>25.829850  </td><td>1.6892055  </td><td>0.21765580 </td><td>66.338854  </td><td>0.69404958 </td><td>0.26549282 </td><td>0.529586065</td><td>44.14544   </td></tr>\n",
       "\t<tr><td>30         </td><td>496.77583  </td><td>80.553581  </td><td>0.5116790  </td><td>0.43575215 </td><td>92.243732  </td><td>0.20535621 </td><td>0.49550760 </td><td>0.549731941</td><td>42.16805   </td></tr>\n",
       "\t<tr><td>30         </td><td>261.28562  </td><td>16.483629  </td><td>3.3100315  </td><td>0.05897293 </td><td>15.308214  </td><td>0.89228352 </td><td>0.50357083 </td><td>0.239288878</td><td>51.75538   </td></tr>\n",
       "\t<tr><td>30         </td><td>421.92905  </td><td>97.740826  </td><td>3.6954132  </td><td>0.63071798 </td><td>43.870431  </td><td>0.58688183 </td><td>0.67234487 </td><td>0.782341848</td><td>46.06913   </td></tr>\n",
       "\t<tr><td>30         </td><td>362.21065  </td><td> 3.572477  </td><td>4.4936570  </td><td>0.88007035 </td><td>99.618287  </td><td>0.88094505 </td><td>0.43866759 </td><td>0.068812180</td><td>48.33022   </td></tr>\n",
       "\t<tr><td>30         </td><td>308.35369  </td><td>82.550522  </td><td>1.4803079  </td><td>0.11926421 </td><td>44.761687  </td><td>0.98306526 </td><td>0.41839219 </td><td>0.190624533</td><td>55.43060   </td></tr>\n",
       "\t<tr><td>30         </td><td>370.10732  </td><td> 4.114588  </td><td>2.6234796  </td><td>0.34156773 </td><td>81.519827  </td><td>0.32036658 </td><td>0.45222689 </td><td>0.043802018</td><td>44.59081   </td></tr>\n",
       "\t<tr><td>30         </td><td>209.78551  </td><td> 5.307582  </td><td>0.7697447  </td><td>0.85939482 </td><td>18.812904  </td><td>0.81556064 </td><td>0.66006938 </td><td>0.123153712</td><td>49.58548   </td></tr>\n",
       "\t<tr><td>30         </td><td>187.56724  </td><td>51.349104  </td><td>3.3438063  </td><td>0.61702112 </td><td>20.374490  </td><td>0.59864803 </td><td>0.20708671 </td><td>0.377884488</td><td>48.38556   </td></tr>\n",
       "\t<tr><td>30         </td><td>484.27418  </td><td>28.262651  </td><td>1.0478970  </td><td>0.15958112 </td><td>95.668522  </td><td>0.86270351 </td><td>0.47242841 </td><td>0.442012486</td><td>42.03604   </td></tr>\n",
       "\t<tr><td>30         </td><td>304.48924  </td><td>43.356757  </td><td>3.9949058  </td><td>0.14495172 </td><td>99.388221  </td><td>0.33065735 </td><td>0.56804264 </td><td>0.789083682</td><td>41.84859   </td></tr>\n",
       "\t<tr><td>30         </td><td>237.89184  </td><td>49.841497  </td><td>2.6132890  </td><td>0.70091386 </td><td>56.330844  </td><td>0.63978828 </td><td>0.36947281 </td><td>0.046631717</td><td>47.16762   </td></tr>\n",
       "\t<tr><td>30         </td><td>429.35362  </td><td> 1.188266  </td><td>0.4285442  </td><td>0.61385632 </td><td>77.818000  </td><td>0.38475187 </td><td>0.81616977 </td><td>0.501988798</td><td>43.27913   </td></tr>\n",
       "\t<tr><td>30         </td><td>218.80517  </td><td>24.948458  </td><td>4.1449879  </td><td>0.06800366 </td><td>98.235495  </td><td>0.26389852 </td><td>0.34533888 </td><td>0.092986771</td><td>47.57498   </td></tr>\n",
       "\t<tr><td>30         </td><td> 42.97026  </td><td>18.876938  </td><td>1.7029472  </td><td>0.33092071 </td><td> 9.313455  </td><td>0.14191936 </td><td>0.43623852 </td><td>0.247718807</td><td>62.47915   </td></tr>\n",
       "\t<tr><td>30         </td><td>211.55580  </td><td>14.694452  </td><td>0.6496062  </td><td>0.67052496 </td><td>38.437853  </td><td>0.74333837 </td><td>0.30813266 </td><td>0.288122695</td><td>49.54751   </td></tr>\n",
       "\t<tr><td>30         </td><td> 89.10651  </td><td>41.186112  </td><td>0.5236139  </td><td>0.23007210 </td><td>58.595874  </td><td>0.92618484 </td><td>0.13804640 </td><td>0.689026008</td><td>58.05833   </td></tr>\n",
       "\t<tr><td>30         </td><td>309.82657  </td><td>29.346832  </td><td>2.1014174  </td><td>0.92326174 </td><td>25.500563  </td><td>0.95336044 </td><td>0.21983866 </td><td>0.006391084</td><td>88.88736   </td></tr>\n",
       "\t<tr><td>30         </td><td>187.03468  </td><td>26.149174  </td><td>1.3483364  </td><td>0.03967006 </td><td>76.000086  </td><td>0.64663058 </td><td>0.77549871 </td><td>0.618781889</td><td>43.41377   </td></tr>\n",
       "\t<tr><td>30         </td><td>112.78570  </td><td>71.094397  </td><td>2.0481520  </td><td>0.47357670 </td><td>30.894127  </td><td>0.06318170 </td><td>0.04341185 </td><td>0.880838591</td><td>94.41411   </td></tr>\n",
       "\t<tr><td>30         </td><td>181.45572  </td><td>69.111081  </td><td>1.1718230  </td><td>0.15434942 </td><td>66.807605  </td><td>0.99393506 </td><td>0.42916233 </td><td>0.303813092</td><td>48.48793   </td></tr>\n",
       "\t<tr><td>30         </td><td>267.26543  </td><td>59.980319  </td><td>3.5591115  </td><td>0.94575559 </td><td>42.011349  </td><td>0.72318684 </td><td>0.21208180 </td><td>0.786316358</td><td>49.07646   </td></tr>\n",
       "\t<tr><td>30         </td><td>398.64183  </td><td>37.948013  </td><td>0.8382159  </td><td>0.97814190 </td><td>16.840550  </td><td>0.37937642 </td><td>0.94191537 </td><td>0.174570792</td><td>48.57160   </td></tr>\n",
       "\t<tr><td>30         </td><td>386.09132  </td><td>18.357766  </td><td>3.8649733  </td><td>0.19826890 </td><td>33.266757  </td><td>0.10747200 </td><td>0.07914372 </td><td>0.946020489</td><td>88.82066   </td></tr>\n",
       "\t<tr><td>30         </td><td>461.46066  </td><td>64.113033  </td><td>3.8208490  </td><td>0.80341982 </td><td>10.479836  </td><td>0.55243810 </td><td>0.70766570 </td><td>0.770229278</td><td>49.10857   </td></tr>\n",
       "\t<tr><td>30         </td><td>234.32666  </td><td>79.514139  </td><td>4.8622873  </td><td>0.85133509 </td><td>34.711122  </td><td>0.10198079 </td><td>0.70289951 </td><td>0.526290378</td><td>46.83409   </td></tr>\n",
       "\t<tr><td>30         </td><td>498.21381  </td><td>49.066915  </td><td>1.7609505  </td><td>0.31587438 </td><td>16.493433  </td><td>0.62701677 </td><td>0.79201951 </td><td>0.516147379</td><td>48.47286   </td></tr>\n",
       "\t<tr><td>30         </td><td>108.53198  </td><td> 5.934689  </td><td>4.2154127  </td><td>0.37974499 </td><td>63.554406  </td><td>0.11121458 </td><td>0.34542538 </td><td>0.848261417</td><td>49.61913   </td></tr>\n",
       "\t<tr><td>30         </td><td>108.95175  </td><td>14.634202  </td><td>0.2255047  </td><td>0.27621496 </td><td>87.765699  </td><td>0.01125575 </td><td>0.12508616 </td><td>0.758276936</td><td>70.63773   </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " size & max\\_links & evidence & sc-bel-prop & prop-likelihood & n\\_init\\_believers & prior-mean & prior-sd & expertise\\_influence & output\\\\\n",
       "\\hline\n",
       "\t 30          & 153.52986   & 17.822423   & 3.5235470   & 0.99942973  & 21.415365   & 0.31318558  & 0.73333450  & 0.388069845 & 48.10765   \\\\\n",
       "\t 30          & 238.41998   & 25.829850   & 1.6892055   & 0.21765580  & 66.338854   & 0.69404958  & 0.26549282  & 0.529586065 & 44.14544   \\\\\n",
       "\t 30          & 496.77583   & 80.553581   & 0.5116790   & 0.43575215  & 92.243732   & 0.20535621  & 0.49550760  & 0.549731941 & 42.16805   \\\\\n",
       "\t 30          & 261.28562   & 16.483629   & 3.3100315   & 0.05897293  & 15.308214   & 0.89228352  & 0.50357083  & 0.239288878 & 51.75538   \\\\\n",
       "\t 30          & 421.92905   & 97.740826   & 3.6954132   & 0.63071798  & 43.870431   & 0.58688183  & 0.67234487  & 0.782341848 & 46.06913   \\\\\n",
       "\t 30          & 362.21065   &  3.572477   & 4.4936570   & 0.88007035  & 99.618287   & 0.88094505  & 0.43866759  & 0.068812180 & 48.33022   \\\\\n",
       "\t 30          & 308.35369   & 82.550522   & 1.4803079   & 0.11926421  & 44.761687   & 0.98306526  & 0.41839219  & 0.190624533 & 55.43060   \\\\\n",
       "\t 30          & 370.10732   &  4.114588   & 2.6234796   & 0.34156773  & 81.519827   & 0.32036658  & 0.45222689  & 0.043802018 & 44.59081   \\\\\n",
       "\t 30          & 209.78551   &  5.307582   & 0.7697447   & 0.85939482  & 18.812904   & 0.81556064  & 0.66006938  & 0.123153712 & 49.58548   \\\\\n",
       "\t 30          & 187.56724   & 51.349104   & 3.3438063   & 0.61702112  & 20.374490   & 0.59864803  & 0.20708671  & 0.377884488 & 48.38556   \\\\\n",
       "\t 30          & 484.27418   & 28.262651   & 1.0478970   & 0.15958112  & 95.668522   & 0.86270351  & 0.47242841  & 0.442012486 & 42.03604   \\\\\n",
       "\t 30          & 304.48924   & 43.356757   & 3.9949058   & 0.14495172  & 99.388221   & 0.33065735  & 0.56804264  & 0.789083682 & 41.84859   \\\\\n",
       "\t 30          & 237.89184   & 49.841497   & 2.6132890   & 0.70091386  & 56.330844   & 0.63978828  & 0.36947281  & 0.046631717 & 47.16762   \\\\\n",
       "\t 30          & 429.35362   &  1.188266   & 0.4285442   & 0.61385632  & 77.818000   & 0.38475187  & 0.81616977  & 0.501988798 & 43.27913   \\\\\n",
       "\t 30          & 218.80517   & 24.948458   & 4.1449879   & 0.06800366  & 98.235495   & 0.26389852  & 0.34533888  & 0.092986771 & 47.57498   \\\\\n",
       "\t 30          &  42.97026   & 18.876938   & 1.7029472   & 0.33092071  &  9.313455   & 0.14191936  & 0.43623852  & 0.247718807 & 62.47915   \\\\\n",
       "\t 30          & 211.55580   & 14.694452   & 0.6496062   & 0.67052496  & 38.437853   & 0.74333837  & 0.30813266  & 0.288122695 & 49.54751   \\\\\n",
       "\t 30          &  89.10651   & 41.186112   & 0.5236139   & 0.23007210  & 58.595874   & 0.92618484  & 0.13804640  & 0.689026008 & 58.05833   \\\\\n",
       "\t 30          & 309.82657   & 29.346832   & 2.1014174   & 0.92326174  & 25.500563   & 0.95336044  & 0.21983866  & 0.006391084 & 88.88736   \\\\\n",
       "\t 30          & 187.03468   & 26.149174   & 1.3483364   & 0.03967006  & 76.000086   & 0.64663058  & 0.77549871  & 0.618781889 & 43.41377   \\\\\n",
       "\t 30          & 112.78570   & 71.094397   & 2.0481520   & 0.47357670  & 30.894127   & 0.06318170  & 0.04341185  & 0.880838591 & 94.41411   \\\\\n",
       "\t 30          & 181.45572   & 69.111081   & 1.1718230   & 0.15434942  & 66.807605   & 0.99393506  & 0.42916233  & 0.303813092 & 48.48793   \\\\\n",
       "\t 30          & 267.26543   & 59.980319   & 3.5591115   & 0.94575559  & 42.011349   & 0.72318684  & 0.21208180  & 0.786316358 & 49.07646   \\\\\n",
       "\t 30          & 398.64183   & 37.948013   & 0.8382159   & 0.97814190  & 16.840550   & 0.37937642  & 0.94191537  & 0.174570792 & 48.57160   \\\\\n",
       "\t 30          & 386.09132   & 18.357766   & 3.8649733   & 0.19826890  & 33.266757   & 0.10747200  & 0.07914372  & 0.946020489 & 88.82066   \\\\\n",
       "\t 30          & 461.46066   & 64.113033   & 3.8208490   & 0.80341982  & 10.479836   & 0.55243810  & 0.70766570  & 0.770229278 & 49.10857   \\\\\n",
       "\t 30          & 234.32666   & 79.514139   & 4.8622873   & 0.85133509  & 34.711122   & 0.10198079  & 0.70289951  & 0.526290378 & 46.83409   \\\\\n",
       "\t 30          & 498.21381   & 49.066915   & 1.7609505   & 0.31587438  & 16.493433   & 0.62701677  & 0.79201951  & 0.516147379 & 48.47286   \\\\\n",
       "\t 30          & 108.53198   &  5.934689   & 4.2154127   & 0.37974499  & 63.554406   & 0.11121458  & 0.34542538  & 0.848261417 & 49.61913   \\\\\n",
       "\t 30          & 108.95175   & 14.634202   & 0.2255047   & 0.27621496  & 87.765699   & 0.01125575  & 0.12508616  & 0.758276936 & 70.63773   \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| size | max_links | evidence | sc-bel-prop | prop-likelihood | n_init_believers | prior-mean | prior-sd | expertise_influence | output |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 30          | 153.52986   | 17.822423   | 3.5235470   | 0.99942973  | 21.415365   | 0.31318558  | 0.73333450  | 0.388069845 | 48.10765    |\n",
       "| 30          | 238.41998   | 25.829850   | 1.6892055   | 0.21765580  | 66.338854   | 0.69404958  | 0.26549282  | 0.529586065 | 44.14544    |\n",
       "| 30          | 496.77583   | 80.553581   | 0.5116790   | 0.43575215  | 92.243732   | 0.20535621  | 0.49550760  | 0.549731941 | 42.16805    |\n",
       "| 30          | 261.28562   | 16.483629   | 3.3100315   | 0.05897293  | 15.308214   | 0.89228352  | 0.50357083  | 0.239288878 | 51.75538    |\n",
       "| 30          | 421.92905   | 97.740826   | 3.6954132   | 0.63071798  | 43.870431   | 0.58688183  | 0.67234487  | 0.782341848 | 46.06913    |\n",
       "| 30          | 362.21065   |  3.572477   | 4.4936570   | 0.88007035  | 99.618287   | 0.88094505  | 0.43866759  | 0.068812180 | 48.33022    |\n",
       "| 30          | 308.35369   | 82.550522   | 1.4803079   | 0.11926421  | 44.761687   | 0.98306526  | 0.41839219  | 0.190624533 | 55.43060    |\n",
       "| 30          | 370.10732   |  4.114588   | 2.6234796   | 0.34156773  | 81.519827   | 0.32036658  | 0.45222689  | 0.043802018 | 44.59081    |\n",
       "| 30          | 209.78551   |  5.307582   | 0.7697447   | 0.85939482  | 18.812904   | 0.81556064  | 0.66006938  | 0.123153712 | 49.58548    |\n",
       "| 30          | 187.56724   | 51.349104   | 3.3438063   | 0.61702112  | 20.374490   | 0.59864803  | 0.20708671  | 0.377884488 | 48.38556    |\n",
       "| 30          | 484.27418   | 28.262651   | 1.0478970   | 0.15958112  | 95.668522   | 0.86270351  | 0.47242841  | 0.442012486 | 42.03604    |\n",
       "| 30          | 304.48924   | 43.356757   | 3.9949058   | 0.14495172  | 99.388221   | 0.33065735  | 0.56804264  | 0.789083682 | 41.84859    |\n",
       "| 30          | 237.89184   | 49.841497   | 2.6132890   | 0.70091386  | 56.330844   | 0.63978828  | 0.36947281  | 0.046631717 | 47.16762    |\n",
       "| 30          | 429.35362   |  1.188266   | 0.4285442   | 0.61385632  | 77.818000   | 0.38475187  | 0.81616977  | 0.501988798 | 43.27913    |\n",
       "| 30          | 218.80517   | 24.948458   | 4.1449879   | 0.06800366  | 98.235495   | 0.26389852  | 0.34533888  | 0.092986771 | 47.57498    |\n",
       "| 30          |  42.97026   | 18.876938   | 1.7029472   | 0.33092071  |  9.313455   | 0.14191936  | 0.43623852  | 0.247718807 | 62.47915    |\n",
       "| 30          | 211.55580   | 14.694452   | 0.6496062   | 0.67052496  | 38.437853   | 0.74333837  | 0.30813266  | 0.288122695 | 49.54751    |\n",
       "| 30          |  89.10651   | 41.186112   | 0.5236139   | 0.23007210  | 58.595874   | 0.92618484  | 0.13804640  | 0.689026008 | 58.05833    |\n",
       "| 30          | 309.82657   | 29.346832   | 2.1014174   | 0.92326174  | 25.500563   | 0.95336044  | 0.21983866  | 0.006391084 | 88.88736    |\n",
       "| 30          | 187.03468   | 26.149174   | 1.3483364   | 0.03967006  | 76.000086   | 0.64663058  | 0.77549871  | 0.618781889 | 43.41377    |\n",
       "| 30          | 112.78570   | 71.094397   | 2.0481520   | 0.47357670  | 30.894127   | 0.06318170  | 0.04341185  | 0.880838591 | 94.41411    |\n",
       "| 30          | 181.45572   | 69.111081   | 1.1718230   | 0.15434942  | 66.807605   | 0.99393506  | 0.42916233  | 0.303813092 | 48.48793    |\n",
       "| 30          | 267.26543   | 59.980319   | 3.5591115   | 0.94575559  | 42.011349   | 0.72318684  | 0.21208180  | 0.786316358 | 49.07646    |\n",
       "| 30          | 398.64183   | 37.948013   | 0.8382159   | 0.97814190  | 16.840550   | 0.37937642  | 0.94191537  | 0.174570792 | 48.57160    |\n",
       "| 30          | 386.09132   | 18.357766   | 3.8649733   | 0.19826890  | 33.266757   | 0.10747200  | 0.07914372  | 0.946020489 | 88.82066    |\n",
       "| 30          | 461.46066   | 64.113033   | 3.8208490   | 0.80341982  | 10.479836   | 0.55243810  | 0.70766570  | 0.770229278 | 49.10857    |\n",
       "| 30          | 234.32666   | 79.514139   | 4.8622873   | 0.85133509  | 34.711122   | 0.10198079  | 0.70289951  | 0.526290378 | 46.83409    |\n",
       "| 30          | 498.21381   | 49.066915   | 1.7609505   | 0.31587438  | 16.493433   | 0.62701677  | 0.79201951  | 0.516147379 | 48.47286    |\n",
       "| 30          | 108.53198   |  5.934689   | 4.2154127   | 0.37974499  | 63.554406   | 0.11121458  | 0.34542538  | 0.848261417 | 49.61913    |\n",
       "| 30          | 108.95175   | 14.634202   | 0.2255047   | 0.27621496  | 87.765699   | 0.01125575  | 0.12508616  | 0.758276936 | 70.63773    |\n",
       "\n"
      ],
      "text/plain": [
       "   size max_links evidence  sc-bel-prop prop-likelihood n_init_believers\n",
       "1  30   153.52986 17.822423 3.5235470   0.99942973      21.415365       \n",
       "2  30   238.41998 25.829850 1.6892055   0.21765580      66.338854       \n",
       "3  30   496.77583 80.553581 0.5116790   0.43575215      92.243732       \n",
       "4  30   261.28562 16.483629 3.3100315   0.05897293      15.308214       \n",
       "5  30   421.92905 97.740826 3.6954132   0.63071798      43.870431       \n",
       "6  30   362.21065  3.572477 4.4936570   0.88007035      99.618287       \n",
       "7  30   308.35369 82.550522 1.4803079   0.11926421      44.761687       \n",
       "8  30   370.10732  4.114588 2.6234796   0.34156773      81.519827       \n",
       "9  30   209.78551  5.307582 0.7697447   0.85939482      18.812904       \n",
       "10 30   187.56724 51.349104 3.3438063   0.61702112      20.374490       \n",
       "11 30   484.27418 28.262651 1.0478970   0.15958112      95.668522       \n",
       "12 30   304.48924 43.356757 3.9949058   0.14495172      99.388221       \n",
       "13 30   237.89184 49.841497 2.6132890   0.70091386      56.330844       \n",
       "14 30   429.35362  1.188266 0.4285442   0.61385632      77.818000       \n",
       "15 30   218.80517 24.948458 4.1449879   0.06800366      98.235495       \n",
       "16 30    42.97026 18.876938 1.7029472   0.33092071       9.313455       \n",
       "17 30   211.55580 14.694452 0.6496062   0.67052496      38.437853       \n",
       "18 30    89.10651 41.186112 0.5236139   0.23007210      58.595874       \n",
       "19 30   309.82657 29.346832 2.1014174   0.92326174      25.500563       \n",
       "20 30   187.03468 26.149174 1.3483364   0.03967006      76.000086       \n",
       "21 30   112.78570 71.094397 2.0481520   0.47357670      30.894127       \n",
       "22 30   181.45572 69.111081 1.1718230   0.15434942      66.807605       \n",
       "23 30   267.26543 59.980319 3.5591115   0.94575559      42.011349       \n",
       "24 30   398.64183 37.948013 0.8382159   0.97814190      16.840550       \n",
       "25 30   386.09132 18.357766 3.8649733   0.19826890      33.266757       \n",
       "26 30   461.46066 64.113033 3.8208490   0.80341982      10.479836       \n",
       "27 30   234.32666 79.514139 4.8622873   0.85133509      34.711122       \n",
       "28 30   498.21381 49.066915 1.7609505   0.31587438      16.493433       \n",
       "29 30   108.53198  5.934689 4.2154127   0.37974499      63.554406       \n",
       "30 30   108.95175 14.634202 0.2255047   0.27621496      87.765699       \n",
       "   prior-mean prior-sd   expertise_influence output  \n",
       "1  0.31318558 0.73333450 0.388069845         48.10765\n",
       "2  0.69404958 0.26549282 0.529586065         44.14544\n",
       "3  0.20535621 0.49550760 0.549731941         42.16805\n",
       "4  0.89228352 0.50357083 0.239288878         51.75538\n",
       "5  0.58688183 0.67234487 0.782341848         46.06913\n",
       "6  0.88094505 0.43866759 0.068812180         48.33022\n",
       "7  0.98306526 0.41839219 0.190624533         55.43060\n",
       "8  0.32036658 0.45222689 0.043802018         44.59081\n",
       "9  0.81556064 0.66006938 0.123153712         49.58548\n",
       "10 0.59864803 0.20708671 0.377884488         48.38556\n",
       "11 0.86270351 0.47242841 0.442012486         42.03604\n",
       "12 0.33065735 0.56804264 0.789083682         41.84859\n",
       "13 0.63978828 0.36947281 0.046631717         47.16762\n",
       "14 0.38475187 0.81616977 0.501988798         43.27913\n",
       "15 0.26389852 0.34533888 0.092986771         47.57498\n",
       "16 0.14191936 0.43623852 0.247718807         62.47915\n",
       "17 0.74333837 0.30813266 0.288122695         49.54751\n",
       "18 0.92618484 0.13804640 0.689026008         58.05833\n",
       "19 0.95336044 0.21983866 0.006391084         88.88736\n",
       "20 0.64663058 0.77549871 0.618781889         43.41377\n",
       "21 0.06318170 0.04341185 0.880838591         94.41411\n",
       "22 0.99393506 0.42916233 0.303813092         48.48793\n",
       "23 0.72318684 0.21208180 0.786316358         49.07646\n",
       "24 0.37937642 0.94191537 0.174570792         48.57160\n",
       "25 0.10747200 0.07914372 0.946020489         88.82066\n",
       "26 0.55243810 0.70766570 0.770229278         49.10857\n",
       "27 0.10198079 0.70289951 0.526290378         46.83409\n",
       "28 0.62701677 0.79201951 0.516147379         48.47286\n",
       "29 0.11121458 0.34542538 0.848261417         49.61913\n",
       "30 0.01125575 0.12508616 0.758276936         70.63773"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc9329e",
   "metadata": {},
   "source": [
    "## Adaptive Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30fa50d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adaptive_initial_data = upload_training_set(model.type,seed.focus,train_ins_Ad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "149c9b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>max_links</th><th scope=col>evidence</th><th scope=col>sc-bel-prop</th><th scope=col>prop-likelihood</th><th scope=col>n_init_believers</th><th scope=col>prior-mean</th><th scope=col>prior-sd</th><th scope=col>expertise_influence</th><th scope=col>output</th><th scope=col>seed</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>379.030421</td><td>33.093892 </td><td>2.3776148 </td><td>0.45018803</td><td>81.489234 </td><td>0.25385494</td><td>0.55607425</td><td>0.44670360</td><td>42.97597  </td><td>8         </td></tr>\n",
       "\t<tr><td>354.720810</td><td>53.770374 </td><td>1.7306876 </td><td>0.39097777</td><td>51.108860 </td><td>0.30752116</td><td>0.74643066</td><td>0.49186844</td><td>45.43132  </td><td>8         </td></tr>\n",
       "\t<tr><td>150.663956</td><td>52.282630 </td><td>2.5397536 </td><td>0.35723122</td><td>49.568888 </td><td>0.46417893</td><td>0.20238519</td><td>0.59242957</td><td>45.53525  </td><td>8         </td></tr>\n",
       "\t<tr><td>310.303729</td><td>37.939215 </td><td>1.6481274 </td><td>0.79260720</td><td>39.472428 </td><td>0.41508232</td><td>0.49821941</td><td>0.54886696</td><td>46.41394  </td><td>8         </td></tr>\n",
       "\t<tr><td>246.681021</td><td>69.824069 </td><td>2.1237128 </td><td>0.49174655</td><td>79.052799 </td><td>0.66834203</td><td>0.87004269</td><td>0.41265428</td><td>43.12122  </td><td>8         </td></tr>\n",
       "\t<tr><td>284.665309</td><td> 2.769528 </td><td>4.5423103 </td><td>0.62618815</td><td>36.565307 </td><td>0.37020836</td><td>0.42145825</td><td>0.70496254</td><td>46.85059  </td><td>8         </td></tr>\n",
       "\t<tr><td> 68.156233</td><td>17.351079 </td><td>3.1303719 </td><td>0.69802720</td><td>46.491671 </td><td>0.35416725</td><td>0.72813793</td><td>0.35974346</td><td>45.94112  </td><td>8         </td></tr>\n",
       "\t<tr><td>395.927951</td><td>72.373656 </td><td>4.0555379 </td><td>0.25140501</td><td>54.704373 </td><td>0.74388255</td><td>0.07464179</td><td>0.76934667</td><td>45.96783  </td><td>8         </td></tr>\n",
       "\t<tr><td>265.703127</td><td>79.724977 </td><td>3.9051546 </td><td>0.71919613</td><td>60.588566 </td><td>0.21410364</td><td>0.32198382</td><td>0.32189261</td><td>47.28248  </td><td>8         </td></tr>\n",
       "\t<tr><td>223.475741</td><td>60.791212 </td><td>3.5232455 </td><td>0.99764996</td><td>11.128286 </td><td>0.93562664</td><td>0.33789561</td><td>0.36937890</td><td>53.15028  </td><td>8         </td></tr>\n",
       "\t<tr><td>421.236560</td><td>66.295107 </td><td>0.3364330 </td><td>0.86289680</td><td>69.176981 </td><td>0.58804706</td><td>0.27009668</td><td>0.95848643</td><td>44.62737  </td><td>8         </td></tr>\n",
       "\t<tr><td>130.072200</td><td>40.463308 </td><td>1.8951732 </td><td>0.23066323</td><td>92.404291 </td><td>0.79270186</td><td>0.18821791</td><td>0.26481386</td><td>52.10164  </td><td>8         </td></tr>\n",
       "\t<tr><td>270.502395</td><td>34.186131 </td><td>1.3370186 </td><td>0.33041472</td><td>93.966827 </td><td>0.29134681</td><td>0.63820563</td><td>0.82755395</td><td>42.25718  </td><td>8         </td></tr>\n",
       "\t<tr><td> 38.009260</td><td>88.114134 </td><td>0.1159223 </td><td>0.75591975</td><td>26.677360 </td><td>0.49086524</td><td>0.51166162</td><td>0.51026560</td><td>49.48517  </td><td>8         </td></tr>\n",
       "\t<tr><td>105.945047</td><td>13.406723 </td><td>2.8871286 </td><td>0.18235217</td><td>24.233537 </td><td>0.91804698</td><td>0.44660403</td><td>0.68047562</td><td>50.16785  </td><td>8         </td></tr>\n",
       "\t<tr><td>329.459638</td><td>74.665187 </td><td>4.7043965 </td><td>0.92781913</td><td>31.755795 </td><td>0.15836933</td><td>0.69424139</td><td>0.85872020</td><td>47.57652  </td><td>8         </td></tr>\n",
       "\t<tr><td>445.433377</td><td>20.163957 </td><td>2.8094550 </td><td>0.64871435</td><td>65.197916 </td><td>0.19703505</td><td>0.01651411</td><td>0.27272424</td><td>85.44612  </td><td>8         </td></tr>\n",
       "\t<tr><td>205.299918</td><td>82.925215 </td><td>4.2510232 </td><td>0.06885088</td><td>40.729035 </td><td>0.50699671</td><td>0.78870993</td><td>0.03180102</td><td>46.33829  </td><td>8         </td></tr>\n",
       "\t<tr><td>172.020981</td><td>90.914017 </td><td>0.7537905 </td><td>0.04963815</td><td>58.502033 </td><td>0.61020586</td><td>0.38904975</td><td>0.87583322</td><td>45.21431  </td><td>8         </td></tr>\n",
       "\t<tr><td>460.201816</td><td>96.436939 </td><td>3.2751746 </td><td>0.41358148</td><td>72.334957 </td><td>0.97636854</td><td>0.24401142</td><td>0.08920294</td><td>77.54047  </td><td>8         </td></tr>\n",
       "\t<tr><td>100.811706</td><td>29.419096 </td><td>0.5983277 </td><td>0.81937961</td><td>73.939981 </td><td>0.54614157</td><td>0.10760606</td><td>0.62401049</td><td>43.65235  </td><td>8         </td></tr>\n",
       "\t<tr><td>344.588980</td><td>56.761968 </td><td>1.2317070 </td><td>0.88367730</td><td>14.666690 </td><td>0.80958359</td><td>0.91395235</td><td>0.90586485</td><td>48.84483  </td><td>8         </td></tr>\n",
       "\t<tr><td>497.046259</td><td> 6.409169 </td><td>3.4342425 </td><td>0.10687218</td><td>17.011417 </td><td>0.11113822</td><td>0.85546841</td><td>0.64210018</td><td>48.49530  </td><td>8         </td></tr>\n",
       "\t<tr><td> 33.715980</td><td>96.878792 </td><td>3.6883370 </td><td>0.01331588</td><td> 9.841476 </td><td>0.06459131</td><td>0.57659928</td><td>0.98300466</td><td>62.21116  </td><td>8         </td></tr>\n",
       "\t<tr><td> 73.873047</td><td>12.010874 </td><td>4.3941673 </td><td>0.28659854</td><td>22.609673 </td><td>0.03020353</td><td>0.04830248</td><td>0.22913679</td><td>95.87331  </td><td>8         </td></tr>\n",
       "\t<tr><td>186.345115</td><td>85.015145 </td><td>0.9108377 </td><td>0.54842970</td><td>87.681003 </td><td>0.07166630</td><td>0.80328097</td><td>0.11883268</td><td>43.34818  </td><td>8         </td></tr>\n",
       "\t<tr><td>  7.535025</td><td>26.249094 </td><td>2.2641867 </td><td>0.94330607</td><td> 1.057592 </td><td>0.83857927</td><td>0.98857611</td><td>0.05042143</td><td>52.57788  </td><td>8         </td></tr>\n",
       "\t<tr><td>468.942075</td><td> 7.031200 </td><td>1.0194360 </td><td>0.14049176</td><td>98.277931 </td><td>0.89776848</td><td>0.96635918</td><td>0.14922773</td><td>41.99267  </td><td>8         </td></tr>\n",
       "\t<tr><td>409.844151</td><td>45.865906 </td><td>0.1690033 </td><td>0.58936029</td><td> 3.752769 </td><td>0.63345464</td><td>0.15235143</td><td>0.18114986</td><td>58.78656  </td><td>8         </td></tr>\n",
       "\t<tr><td>158.671688</td><td>49.715070 </td><td>4.9558383 </td><td>0.52870032</td><td>85.371960 </td><td>0.70624448</td><td>0.62319670</td><td>0.75789638</td><td>42.77706  </td><td>8         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllll}\n",
       " max\\_links & evidence & sc-bel-prop & prop-likelihood & n\\_init\\_believers & prior-mean & prior-sd & expertise\\_influence & output & seed\\\\\n",
       "\\hline\n",
       "\t 379.030421 & 33.093892  & 2.3776148  & 0.45018803 & 81.489234  & 0.25385494 & 0.55607425 & 0.44670360 & 42.97597   & 8         \\\\\n",
       "\t 354.720810 & 53.770374  & 1.7306876  & 0.39097777 & 51.108860  & 0.30752116 & 0.74643066 & 0.49186844 & 45.43132   & 8         \\\\\n",
       "\t 150.663956 & 52.282630  & 2.5397536  & 0.35723122 & 49.568888  & 0.46417893 & 0.20238519 & 0.59242957 & 45.53525   & 8         \\\\\n",
       "\t 310.303729 & 37.939215  & 1.6481274  & 0.79260720 & 39.472428  & 0.41508232 & 0.49821941 & 0.54886696 & 46.41394   & 8         \\\\\n",
       "\t 246.681021 & 69.824069  & 2.1237128  & 0.49174655 & 79.052799  & 0.66834203 & 0.87004269 & 0.41265428 & 43.12122   & 8         \\\\\n",
       "\t 284.665309 &  2.769528  & 4.5423103  & 0.62618815 & 36.565307  & 0.37020836 & 0.42145825 & 0.70496254 & 46.85059   & 8         \\\\\n",
       "\t  68.156233 & 17.351079  & 3.1303719  & 0.69802720 & 46.491671  & 0.35416725 & 0.72813793 & 0.35974346 & 45.94112   & 8         \\\\\n",
       "\t 395.927951 & 72.373656  & 4.0555379  & 0.25140501 & 54.704373  & 0.74388255 & 0.07464179 & 0.76934667 & 45.96783   & 8         \\\\\n",
       "\t 265.703127 & 79.724977  & 3.9051546  & 0.71919613 & 60.588566  & 0.21410364 & 0.32198382 & 0.32189261 & 47.28248   & 8         \\\\\n",
       "\t 223.475741 & 60.791212  & 3.5232455  & 0.99764996 & 11.128286  & 0.93562664 & 0.33789561 & 0.36937890 & 53.15028   & 8         \\\\\n",
       "\t 421.236560 & 66.295107  & 0.3364330  & 0.86289680 & 69.176981  & 0.58804706 & 0.27009668 & 0.95848643 & 44.62737   & 8         \\\\\n",
       "\t 130.072200 & 40.463308  & 1.8951732  & 0.23066323 & 92.404291  & 0.79270186 & 0.18821791 & 0.26481386 & 52.10164   & 8         \\\\\n",
       "\t 270.502395 & 34.186131  & 1.3370186  & 0.33041472 & 93.966827  & 0.29134681 & 0.63820563 & 0.82755395 & 42.25718   & 8         \\\\\n",
       "\t  38.009260 & 88.114134  & 0.1159223  & 0.75591975 & 26.677360  & 0.49086524 & 0.51166162 & 0.51026560 & 49.48517   & 8         \\\\\n",
       "\t 105.945047 & 13.406723  & 2.8871286  & 0.18235217 & 24.233537  & 0.91804698 & 0.44660403 & 0.68047562 & 50.16785   & 8         \\\\\n",
       "\t 329.459638 & 74.665187  & 4.7043965  & 0.92781913 & 31.755795  & 0.15836933 & 0.69424139 & 0.85872020 & 47.57652   & 8         \\\\\n",
       "\t 445.433377 & 20.163957  & 2.8094550  & 0.64871435 & 65.197916  & 0.19703505 & 0.01651411 & 0.27272424 & 85.44612   & 8         \\\\\n",
       "\t 205.299918 & 82.925215  & 4.2510232  & 0.06885088 & 40.729035  & 0.50699671 & 0.78870993 & 0.03180102 & 46.33829   & 8         \\\\\n",
       "\t 172.020981 & 90.914017  & 0.7537905  & 0.04963815 & 58.502033  & 0.61020586 & 0.38904975 & 0.87583322 & 45.21431   & 8         \\\\\n",
       "\t 460.201816 & 96.436939  & 3.2751746  & 0.41358148 & 72.334957  & 0.97636854 & 0.24401142 & 0.08920294 & 77.54047   & 8         \\\\\n",
       "\t 100.811706 & 29.419096  & 0.5983277  & 0.81937961 & 73.939981  & 0.54614157 & 0.10760606 & 0.62401049 & 43.65235   & 8         \\\\\n",
       "\t 344.588980 & 56.761968  & 1.2317070  & 0.88367730 & 14.666690  & 0.80958359 & 0.91395235 & 0.90586485 & 48.84483   & 8         \\\\\n",
       "\t 497.046259 &  6.409169  & 3.4342425  & 0.10687218 & 17.011417  & 0.11113822 & 0.85546841 & 0.64210018 & 48.49530   & 8         \\\\\n",
       "\t  33.715980 & 96.878792  & 3.6883370  & 0.01331588 &  9.841476  & 0.06459131 & 0.57659928 & 0.98300466 & 62.21116   & 8         \\\\\n",
       "\t  73.873047 & 12.010874  & 4.3941673  & 0.28659854 & 22.609673  & 0.03020353 & 0.04830248 & 0.22913679 & 95.87331   & 8         \\\\\n",
       "\t 186.345115 & 85.015145  & 0.9108377  & 0.54842970 & 87.681003  & 0.07166630 & 0.80328097 & 0.11883268 & 43.34818   & 8         \\\\\n",
       "\t   7.535025 & 26.249094  & 2.2641867  & 0.94330607 &  1.057592  & 0.83857927 & 0.98857611 & 0.05042143 & 52.57788   & 8         \\\\\n",
       "\t 468.942075 &  7.031200  & 1.0194360  & 0.14049176 & 98.277931  & 0.89776848 & 0.96635918 & 0.14922773 & 41.99267   & 8         \\\\\n",
       "\t 409.844151 & 45.865906  & 0.1690033  & 0.58936029 &  3.752769  & 0.63345464 & 0.15235143 & 0.18114986 & 58.78656   & 8         \\\\\n",
       "\t 158.671688 & 49.715070  & 4.9558383  & 0.52870032 & 85.371960  & 0.70624448 & 0.62319670 & 0.75789638 & 42.77706   & 8         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| max_links | evidence | sc-bel-prop | prop-likelihood | n_init_believers | prior-mean | prior-sd | expertise_influence | output | seed |\n",
       "|---|---|---|---|---|---|---|---|---|---|\n",
       "| 379.030421 | 33.093892  | 2.3776148  | 0.45018803 | 81.489234  | 0.25385494 | 0.55607425 | 0.44670360 | 42.97597   | 8          |\n",
       "| 354.720810 | 53.770374  | 1.7306876  | 0.39097777 | 51.108860  | 0.30752116 | 0.74643066 | 0.49186844 | 45.43132   | 8          |\n",
       "| 150.663956 | 52.282630  | 2.5397536  | 0.35723122 | 49.568888  | 0.46417893 | 0.20238519 | 0.59242957 | 45.53525   | 8          |\n",
       "| 310.303729 | 37.939215  | 1.6481274  | 0.79260720 | 39.472428  | 0.41508232 | 0.49821941 | 0.54886696 | 46.41394   | 8          |\n",
       "| 246.681021 | 69.824069  | 2.1237128  | 0.49174655 | 79.052799  | 0.66834203 | 0.87004269 | 0.41265428 | 43.12122   | 8          |\n",
       "| 284.665309 |  2.769528  | 4.5423103  | 0.62618815 | 36.565307  | 0.37020836 | 0.42145825 | 0.70496254 | 46.85059   | 8          |\n",
       "|  68.156233 | 17.351079  | 3.1303719  | 0.69802720 | 46.491671  | 0.35416725 | 0.72813793 | 0.35974346 | 45.94112   | 8          |\n",
       "| 395.927951 | 72.373656  | 4.0555379  | 0.25140501 | 54.704373  | 0.74388255 | 0.07464179 | 0.76934667 | 45.96783   | 8          |\n",
       "| 265.703127 | 79.724977  | 3.9051546  | 0.71919613 | 60.588566  | 0.21410364 | 0.32198382 | 0.32189261 | 47.28248   | 8          |\n",
       "| 223.475741 | 60.791212  | 3.5232455  | 0.99764996 | 11.128286  | 0.93562664 | 0.33789561 | 0.36937890 | 53.15028   | 8          |\n",
       "| 421.236560 | 66.295107  | 0.3364330  | 0.86289680 | 69.176981  | 0.58804706 | 0.27009668 | 0.95848643 | 44.62737   | 8          |\n",
       "| 130.072200 | 40.463308  | 1.8951732  | 0.23066323 | 92.404291  | 0.79270186 | 0.18821791 | 0.26481386 | 52.10164   | 8          |\n",
       "| 270.502395 | 34.186131  | 1.3370186  | 0.33041472 | 93.966827  | 0.29134681 | 0.63820563 | 0.82755395 | 42.25718   | 8          |\n",
       "|  38.009260 | 88.114134  | 0.1159223  | 0.75591975 | 26.677360  | 0.49086524 | 0.51166162 | 0.51026560 | 49.48517   | 8          |\n",
       "| 105.945047 | 13.406723  | 2.8871286  | 0.18235217 | 24.233537  | 0.91804698 | 0.44660403 | 0.68047562 | 50.16785   | 8          |\n",
       "| 329.459638 | 74.665187  | 4.7043965  | 0.92781913 | 31.755795  | 0.15836933 | 0.69424139 | 0.85872020 | 47.57652   | 8          |\n",
       "| 445.433377 | 20.163957  | 2.8094550  | 0.64871435 | 65.197916  | 0.19703505 | 0.01651411 | 0.27272424 | 85.44612   | 8          |\n",
       "| 205.299918 | 82.925215  | 4.2510232  | 0.06885088 | 40.729035  | 0.50699671 | 0.78870993 | 0.03180102 | 46.33829   | 8          |\n",
       "| 172.020981 | 90.914017  | 0.7537905  | 0.04963815 | 58.502033  | 0.61020586 | 0.38904975 | 0.87583322 | 45.21431   | 8          |\n",
       "| 460.201816 | 96.436939  | 3.2751746  | 0.41358148 | 72.334957  | 0.97636854 | 0.24401142 | 0.08920294 | 77.54047   | 8          |\n",
       "| 100.811706 | 29.419096  | 0.5983277  | 0.81937961 | 73.939981  | 0.54614157 | 0.10760606 | 0.62401049 | 43.65235   | 8          |\n",
       "| 344.588980 | 56.761968  | 1.2317070  | 0.88367730 | 14.666690  | 0.80958359 | 0.91395235 | 0.90586485 | 48.84483   | 8          |\n",
       "| 497.046259 |  6.409169  | 3.4342425  | 0.10687218 | 17.011417  | 0.11113822 | 0.85546841 | 0.64210018 | 48.49530   | 8          |\n",
       "|  33.715980 | 96.878792  | 3.6883370  | 0.01331588 |  9.841476  | 0.06459131 | 0.57659928 | 0.98300466 | 62.21116   | 8          |\n",
       "|  73.873047 | 12.010874  | 4.3941673  | 0.28659854 | 22.609673  | 0.03020353 | 0.04830248 | 0.22913679 | 95.87331   | 8          |\n",
       "| 186.345115 | 85.015145  | 0.9108377  | 0.54842970 | 87.681003  | 0.07166630 | 0.80328097 | 0.11883268 | 43.34818   | 8          |\n",
       "|   7.535025 | 26.249094  | 2.2641867  | 0.94330607 |  1.057592  | 0.83857927 | 0.98857611 | 0.05042143 | 52.57788   | 8          |\n",
       "| 468.942075 |  7.031200  | 1.0194360  | 0.14049176 | 98.277931  | 0.89776848 | 0.96635918 | 0.14922773 | 41.99267   | 8          |\n",
       "| 409.844151 | 45.865906  | 0.1690033  | 0.58936029 |  3.752769  | 0.63345464 | 0.15235143 | 0.18114986 | 58.78656   | 8          |\n",
       "| 158.671688 | 49.715070  | 4.9558383  | 0.52870032 | 85.371960  | 0.70624448 | 0.62319670 | 0.75789638 | 42.77706   | 8          |\n",
       "\n"
      ],
      "text/plain": [
       "   max_links  evidence  sc-bel-prop prop-likelihood n_init_believers prior-mean\n",
       "1  379.030421 33.093892 2.3776148   0.45018803      81.489234        0.25385494\n",
       "2  354.720810 53.770374 1.7306876   0.39097777      51.108860        0.30752116\n",
       "3  150.663956 52.282630 2.5397536   0.35723122      49.568888        0.46417893\n",
       "4  310.303729 37.939215 1.6481274   0.79260720      39.472428        0.41508232\n",
       "5  246.681021 69.824069 2.1237128   0.49174655      79.052799        0.66834203\n",
       "6  284.665309  2.769528 4.5423103   0.62618815      36.565307        0.37020836\n",
       "7   68.156233 17.351079 3.1303719   0.69802720      46.491671        0.35416725\n",
       "8  395.927951 72.373656 4.0555379   0.25140501      54.704373        0.74388255\n",
       "9  265.703127 79.724977 3.9051546   0.71919613      60.588566        0.21410364\n",
       "10 223.475741 60.791212 3.5232455   0.99764996      11.128286        0.93562664\n",
       "11 421.236560 66.295107 0.3364330   0.86289680      69.176981        0.58804706\n",
       "12 130.072200 40.463308 1.8951732   0.23066323      92.404291        0.79270186\n",
       "13 270.502395 34.186131 1.3370186   0.33041472      93.966827        0.29134681\n",
       "14  38.009260 88.114134 0.1159223   0.75591975      26.677360        0.49086524\n",
       "15 105.945047 13.406723 2.8871286   0.18235217      24.233537        0.91804698\n",
       "16 329.459638 74.665187 4.7043965   0.92781913      31.755795        0.15836933\n",
       "17 445.433377 20.163957 2.8094550   0.64871435      65.197916        0.19703505\n",
       "18 205.299918 82.925215 4.2510232   0.06885088      40.729035        0.50699671\n",
       "19 172.020981 90.914017 0.7537905   0.04963815      58.502033        0.61020586\n",
       "20 460.201816 96.436939 3.2751746   0.41358148      72.334957        0.97636854\n",
       "21 100.811706 29.419096 0.5983277   0.81937961      73.939981        0.54614157\n",
       "22 344.588980 56.761968 1.2317070   0.88367730      14.666690        0.80958359\n",
       "23 497.046259  6.409169 3.4342425   0.10687218      17.011417        0.11113822\n",
       "24  33.715980 96.878792 3.6883370   0.01331588       9.841476        0.06459131\n",
       "25  73.873047 12.010874 4.3941673   0.28659854      22.609673        0.03020353\n",
       "26 186.345115 85.015145 0.9108377   0.54842970      87.681003        0.07166630\n",
       "27   7.535025 26.249094 2.2641867   0.94330607       1.057592        0.83857927\n",
       "28 468.942075  7.031200 1.0194360   0.14049176      98.277931        0.89776848\n",
       "29 409.844151 45.865906 0.1690033   0.58936029       3.752769        0.63345464\n",
       "30 158.671688 49.715070 4.9558383   0.52870032      85.371960        0.70624448\n",
       "   prior-sd   expertise_influence output   seed\n",
       "1  0.55607425 0.44670360          42.97597 8   \n",
       "2  0.74643066 0.49186844          45.43132 8   \n",
       "3  0.20238519 0.59242957          45.53525 8   \n",
       "4  0.49821941 0.54886696          46.41394 8   \n",
       "5  0.87004269 0.41265428          43.12122 8   \n",
       "6  0.42145825 0.70496254          46.85059 8   \n",
       "7  0.72813793 0.35974346          45.94112 8   \n",
       "8  0.07464179 0.76934667          45.96783 8   \n",
       "9  0.32198382 0.32189261          47.28248 8   \n",
       "10 0.33789561 0.36937890          53.15028 8   \n",
       "11 0.27009668 0.95848643          44.62737 8   \n",
       "12 0.18821791 0.26481386          52.10164 8   \n",
       "13 0.63820563 0.82755395          42.25718 8   \n",
       "14 0.51166162 0.51026560          49.48517 8   \n",
       "15 0.44660403 0.68047562          50.16785 8   \n",
       "16 0.69424139 0.85872020          47.57652 8   \n",
       "17 0.01651411 0.27272424          85.44612 8   \n",
       "18 0.78870993 0.03180102          46.33829 8   \n",
       "19 0.38904975 0.87583322          45.21431 8   \n",
       "20 0.24401142 0.08920294          77.54047 8   \n",
       "21 0.10760606 0.62401049          43.65235 8   \n",
       "22 0.91395235 0.90586485          48.84483 8   \n",
       "23 0.85546841 0.64210018          48.49530 8   \n",
       "24 0.57659928 0.98300466          62.21116 8   \n",
       "25 0.04830248 0.22913679          95.87331 8   \n",
       "26 0.80328097 0.11883268          43.34818 8   \n",
       "27 0.98857611 0.05042143          52.57788 8   \n",
       "28 0.96635918 0.14922773          41.99267 8   \n",
       "29 0.15235143 0.18114986          58.78656 8   \n",
       "30 0.62319670 0.75789638          42.77706 8   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adaptive_initial_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08345fa",
   "metadata": {},
   "source": [
    "### Adaptive & Feature Elimination Train & Test Metamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ef3c3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"seed : 8  Adaptive Sampling with Feature Selection section start time : 2022-01-08 11:36:34\"\n",
      "[1] \"seed : 8   rep : 1  Adaptive Sampling with Feature Selection section start time : 2022-01-08 11:36:34\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:36:35\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:39:19\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:39:19\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:50:17\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:50:17\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:51:52\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:51:52\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:54:44\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:54:44\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:56:49\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:56:49\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 11:59:28\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 11:59:28\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:02:12\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:02:12\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:05:02\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:05:02\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:09:31\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:09:31\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:11:57\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 2  Adaptive Sampling with Feature Selection section start time : 2022-01-08 12:11:57\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:11:57\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:14:50\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:14:50\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:16:31\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:16:31\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:19:18\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:19:18\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:21:59\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:21:59\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:29:31\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:29:31\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:32:01\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:32:01\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:34:25\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:34:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:37:05\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:37:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:39:31\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:39:31\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:42:04\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 3  Adaptive Sampling with Feature Selection section start time : 2022-01-08 12:42:04\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:42:04\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:43:46\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:43:46\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:46:48\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:46:48\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:49:08\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:49:08\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:54:57\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:54:57\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 12:58:21\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 12:58:21\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:00:47\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:00:47\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:04:52\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:04:52\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:08:09\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:08:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:10:38\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:10:38\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:13:15\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 4  Adaptive Sampling with Feature Selection section start time : 2022-01-08 13:13:15\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:13:15\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:16:17\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:16:17\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:19:29\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:19:29\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:26:54\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:26:54\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:30:35\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:30:35\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:32:41\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:32:41\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:36:14\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:36:15\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:39:01\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:39:01\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:41:33\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:41:34\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:44:03\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:44:03\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:46:23\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 5  Adaptive Sampling with Feature Selection section start time : 2022-01-08 13:46:23\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:46:23\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:49:38\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:49:38\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:55:14\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:55:14\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 13:57:56\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 13:57:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:00:46\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:00:46\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:02:39\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:02:39\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:05:10\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:05:11\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:09:33\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:09:33\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:12:03\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:12:03\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:14:58\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:14:58\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:18:14\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 6  Adaptive Sampling with Feature Selection section start time : 2022-01-08 14:18:14\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:18:14\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:23:18\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:23:18\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:25:29\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:25:29\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:27:32\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:27:32\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:30:13\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:30:13\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:34:09\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:34:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:38:43\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:38:43\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:41:09\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:41:09\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:44:28\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:44:29\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:47:25\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:47:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:50:04\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 7  Adaptive Sampling with Feature Selection section start time : 2022-01-08 14:50:04\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:50:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:52:06\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:52:06\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:55:05\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:55:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 14:57:43\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 14:57:43\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:02:04\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:02:04\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:04:37\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:04:37\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:07:39\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:07:40\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:11:16\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:11:16\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:15:05\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:15:05\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:17:57\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:17:57\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:21:20\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 8  Adaptive Sampling with Feature Selection section start time : 2022-01-08 15:21:20\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:21:20\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:25:04\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:25:04\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:28:51\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:28:51\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:31:41\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:31:41\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:35:28\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:35:28\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:38:12\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:38:12\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:41:25\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:41:25\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:45:00\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:45:00\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:48:40\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:48:40\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:55:45\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:55:45\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 15:58:59\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 9  Adaptive Sampling with Feature Selection section start time : 2022-01-08 15:58:59\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 15:58:59\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:01:19\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:01:19\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:04:35\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:04:35\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:06:59\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:06:59\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:09:46\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:09:46\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:12:57\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:12:57\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:15:55\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:15:56\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:18:48\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:18:48\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:25:38\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:25:38\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:28:22\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:28:22\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:31:28\"\n",
      "[1] 11\n",
      "[1] \"seed : 8   rep : 10  Adaptive Sampling with Feature Selection section start time : 2022-01-08 16:31:28\"\n",
      "[1] 1\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:31:28\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:34:18\"\n",
      "[1] 2\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:34:18\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:37:21\"\n",
      "[1] 3\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:37:21\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:40:01\"\n",
      "[1] 4\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:40:01\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:43:12\"\n",
      "[1] 5\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:43:12\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:45:00\"\n",
      "[1] 6\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:45:00\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:47:38\"\n",
      "[1] 7\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:47:39\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:54:22\"\n",
      "[1] 8\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:54:22\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 16:57:28\"\n",
      "[1] 9\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 16:57:28\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 17:00:23\"\n",
      "[1] 10\n",
      "[1] \"ABM train_candidate run start time : 2022-01-08 17:00:23\"\n",
      "[1] \"ABM train_candidate run end time : 2022-01-08 17:02:53\"\n",
      "[1] 11\n"
     ]
    }
   ],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "for(i in seed.focus){ print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "    for (r in metarep){ print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                    \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                    \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    }\n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13da08d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample.type = paste0(\"AdFe_\",selection_metric)\n",
    "sample.folder = paste0(sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,sample.folder), showWarnings = FALSE)\n",
    "\n",
    "models.folder = paste0(\"models_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,models.folder), showWarnings = FALSE)\n",
    "\n",
    "PL.folder = paste0(\"PL_\",sample.type,\"/\")\n",
    "dir.create(file.path(folder.path, output.folder,PL.folder), showWarnings = FALSE)\n",
    "\n",
    "i = 0\n",
    "    \n",
    "    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Selection section start time : \",Sys.time()))    \n",
    "r = 2 \n",
    "        print(paste0(\"seed : \", i,\"   rep : \", r, \"  Adaptive Sampling with Feature Selection section start time : \", Sys.time()))\n",
    "        set.seed(i + r)\n",
    "            \n",
    "        training_set_Ad = copy(adaptive_initial_data[seed == i, .SD, .SDcols = -c(\"seed\")])\n",
    "        train_candidates_table = data.table()\n",
    "        \n",
    "        columns_left = feature_names # reset at the beginning of each iteration\n",
    "        total_numof_eliminated_vars <- 0 # reset at the beginning of each iteration\n",
    "        eliminated_columns = c()\n",
    "    \n",
    "        iteration_history = data.table(\"seed\" = integer(),\"rep\" = integer(),\"iter_no\" = integer()\n",
    "                              ,\"IsFeatureEliminated\" = logical(), \"IsDataSelected\" = logical()\n",
    "                              ,\"NumOfEliminated\" = integer(), \"RankedUpd\" = logical())\n",
    "        iter = 1\n",
    "        while(iter <= iteration_budget){   \n",
    "            print(iter)\n",
    "            run_log_entry()\n",
    "    \n",
    "            trainx = training_set_Ad[,.SD, .SDcols = columns_left]\n",
    "            trainy = training_set_Ad$output\n",
    "        \n",
    "            run_step_log_entry(\"Model Training Start.\")\n",
    "            \n",
    "            # Train the model\n",
    "            model_Sub <- randomForest( x = trainx, y =  trainy,importance = TRUE\n",
    "                                      ,ntree = ntree, nperm = nperm\n",
    "                                      ,mtry = mtry_default(columns_left) * mtry.multiplier)\n",
    "                model_Sub.name = paste0(\"model_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r)\n",
    "                model_Sub.path = paste0(outputs.path,models.folder, paste0(model_Sub.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                saveRDS(model_Sub, model_Sub.path)\n",
    "        \n",
    "            iteration_history= rbind(iteration_history,data.table(i,r,iter,0,0,0,0), use.names = FALSE)\n",
    "            # update VIM or not\n",
    "            if (elimination.type == \"RFE\" | (elimination.type == \"NRFE\" & (length(columns_left) == length(feature_names)))){\n",
    "                ranked_features = get_variable_importance(model_Sub)\n",
    "                iteration_history[iter]$RankedUpd= 1 \n",
    "                \n",
    "            }     \n",
    "       \n",
    "            # write errors \n",
    "            obb_err = obb_error_func(model_Sub)     \n",
    "            fwrite(data.table(iter,obb_error = obb_err,seed = i,rep = r)\n",
    "                   ,paste0(outputs.path,sample.folder,model.type,\"_\",\"obb_error_\",sample.type,\".csv\") ,append = TRUE)\n",
    "        \n",
    "            write_test_accuracy(i,r,iter,model_Sub,test_set, error_type)\n",
    "            write_importance.rf(i,r,iter,model_Sub,sample.type)#last one=sample_type\n",
    "        \n",
    "            if(iter != iteration_budget){ # below efforts are unnecessary when the budget is reached. \n",
    "                \n",
    "                run_step_log_entry(\"Sample Selection Start.\")\n",
    "         \n",
    "                ### SAMPLE SELECTION ###    \n",
    "                #select samples first but not to add to the training set until eliminated_features are specified.\n",
    "                # select new data candidates before elimination\n",
    "                ## sample selection from unlabeled data select candidates\n",
    "                unlabeled_set <- refresh_sample_pool(i + r + iter, columns_left)\n",
    "                train_candidates = sample_selection(selected_ins, unlabeled_set, model_Sub,selection_metric)\n",
    "                \n",
    "                fwrite(data.table(setcolorder(train_candidates, feature_names), \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_ABM_train_candidates_table_\"\n",
    "                       ,sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "\n",
    "                run_step_log_entry(\"ABM Run Start.\")\n",
    "                \n",
    "                # run ABM to find outputs of train candidates\n",
    "                print(paste0(\"ABM train_candidate run start time : \",Sys.time()))\n",
    "                train_candidates = run_ABM(nofrep, selected_ins, train_candidates)\n",
    "                \n",
    "                run_step_log_entry(\"ABM Run End.\")\n",
    "                \n",
    "                print(paste0(\"ABM train_candidate run end time : \",Sys.time()))\n",
    "                \n",
    "                fwrite(data.table(train_candidates, \"iter\" = iter, \"seed\" = i, \"rep\" = r)\n",
    "                       ,paste0(outputs.path,sample.folder,model.type,\"_train_candidates_table_\",sample.type,\".csv\"),append = TRUE )      \n",
    "\n",
    "                ### SAMPLE SELECTION ENDS ###\n",
    "                \n",
    "                ### FEATURE ELIMINATION ###\n",
    "                if(elimination_start_iter <= iter & length(columns_left) >= 2){ #######ilk deneylerde eşitlik yoktu.\n",
    "                    check_elim = TRUE \n",
    "                    apply_elim = FALSE\n",
    "                    # \n",
    "                ### FEATURE ELIMINATION PART I ###\n",
    "                #decide how many features will be eliminated\n",
    "                    elim_check_iter = 1\n",
    "                    h = floor(length(columns_left) * (p^elim_check_iter))\n",
    "                    while(check_elim){\n",
    "                    \n",
    "                        run_step_log_entry(\"Feature Selection Start.\")\n",
    "    \n",
    "                        # Assume as if feature(s) will be eliminated\n",
    "                        feature_elimination_result = feature_elimination(h, columns_left, ranked_features)\n",
    "                        planned_columns_left = feature_elimination_result[[1]]\n",
    "                        \n",
    "                        run_step_log_entry(\"New Random Forest Model Generation.\")\n",
    "                        \n",
    "                        model_Sub_afterElim <- randomForest(  x = training_set_Ad[,.SD, .SDcols = planned_columns_left]\n",
    "                                                             ,y =  training_set_Ad$output\n",
    "                                                             ,importance = TRUE, nperm = nperm\n",
    "                                                             ,ntree = ntree\n",
    "                                                            , mtry = mtry_default(planned_columns_left) * mtry.multiplier)        \n",
    "                            model_Sub_afterElim.name = paste0(\"model_afterElim_\",sample.type,\"_\", iter, \"_seed_\", i, \"_rep_\",r,\"_h_\",h)\n",
    "                            model_Sub_afterElim.path = paste0(outputs.path,models.folder, paste0(model_Sub_afterElim.name,\"_size_\",train_ins_Ad, \".rds\"))  # to save the model\n",
    "                            saveRDS(model_Sub_afterElim, model_Sub_afterElim.path)\n",
    "\n",
    "                        run_step_log_entry(\"New Random Forest Model OOB Calculation.\")\n",
    "\n",
    "                        new_oob = obb_error_func(model_Sub_afterElim)\n",
    "                    \n",
    "                        if(new_oob < (obb_err + obb_err * oob_allowance)){ \n",
    "\n",
    "                            run_step_log_entry(\"New Random Forest Model Selected.\")\n",
    "\n",
    "                            check_elim = FALSE \n",
    "                            apply_elim = TRUE                            \n",
    "\n",
    "                        } else {\n",
    "                            \n",
    "                            run_step_log_entry(\"New Random Forest Model is not Selected.\")\n",
    "\n",
    "                            elim_check_iter = elim_check_iter + 1\n",
    "                            h_upd = floor(length(columns_left) * (p^elim_check_iter)) \n",
    "                            \n",
    "                            if(h_upd == h){ # if h does not change\n",
    "                                check_elim = FALSE    \n",
    "                            }\n",
    "                            \n",
    "                            h = copy(h_upd)\n",
    "                        }\n",
    "                     }             \n",
    "               ### FEATURE SELECTION PART II ###\n",
    "               # really eliminate \n",
    "                    if(apply_elim){\n",
    "                        \n",
    "                        run_step_log_entry(\"Feature Elimination Applied.\")\n",
    "                        \n",
    "                        # update iteration_history\n",
    "                        iteration_history[iter]$IsFeatureEliminated= 1\n",
    "                        iteration_history[iter]$NumOfEliminated= length(columns_left) - length(planned_columns_left)\n",
    "                \n",
    "                        columns_left = planned_columns_left\n",
    "                        eliminated_columns =  feature_elimination_result[[4]]\n",
    "\n",
    "                        run_step_log_entry(\"Eliminated Columns Recorded.\")\n",
    "                    \n",
    "                    }         \n",
    "               }\n",
    "              ### FEATURE SELECTION ENDS ###\n",
    "            \n",
    "              # add labeled candidates to the train data\n",
    "              training_set_Ad = rbind(training_set_Ad, train_candidates[, -c(\"idx\")],use.names = TRUE)\n",
    "              # update iteration_history\n",
    "              iteration_history[iter]$IsDataSelected= 1\n",
    "\n",
    "                run_step_log_entry(\"Labeled Data Added to Training Set.\")\n",
    "  \n",
    "            }\n",
    "            fwrite(iteration_history[iter],paste0(outputs.path,sample.folder,model.type,\"_iteration_history_\",sample.type,\".csv\"),append = TRUE )       \n",
    "\n",
    "            run_step_log_entry(paste0(\"Iteration history Updated. Iteration \", iter, \" Ends.\"))\n",
    "\n",
    "            iter = iter + 1\n",
    "\n",
    "        }\n",
    "        \n",
    "        run_step_log_entry(\"Final Train Data File Recorded.\")\n",
    "    \n",
    "        fwrite(data.table(training_set_Ad, \"seed\" = i,\"rep\" = r),paste0(outputs.path,sample.folder,model.type,\"_FinalTrainData_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(\"Eliminated Columns File Recorded.\")\n",
    "\n",
    "        fwrite(data.table(\"seed\" = i,\"rep\" = r, \"elim_cols\" =  eliminated_columns),paste0(outputs.path,sample.folder,model.type,\"_EliminatedColumns_\",sample.type,\".csv\") ,append = TRUE)\n",
    "\n",
    "        run_step_log_entry(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))       \n",
    "                       \n",
    "    ##    print(paste0(\"seed : \",i,\"   rep : \", r,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    \n",
    "    \n",
    "    run_step_log_entry(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))                 \n",
    "                     \n",
    "##    print(paste0(\"seed : \",i,\"  Adaptive Sampling with Feature Elimination section end time : \",Sys.time()))\n",
    "    #rm(training_set_Ad,predictedLabels_table,train_candidates_table)      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f30563d",
   "metadata": {},
   "source": [
    "## Quit NL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92aeb987",
   "metadata": {},
   "outputs": [],
   "source": [
    "NLQuit(nl.obj = nl.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0949b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
